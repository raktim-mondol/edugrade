{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb1f8e8e",
   "metadata": {},
   "source": [
    "Part1:\n",
    "1.Optimizing the clean method & Using 5 fold cross validation rather than train_test_split to make the output more stable and reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3c173dfc-bc9a-42cf-b370-5f84a6831e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 6)\n",
      "topic\n",
      "dark         490\n",
      "sadness      376\n",
      "personal     347\n",
      "lifestyle    205\n",
      "emotion       82\n",
      "Name: count, dtype: int64\n",
      "                            artist_name         track_name  release_date  \\\n",
      "0                                loving  the not real lake          2016   \n",
      "1                               incubus    into the summer          2019   \n",
      "2                             reignwolf           hardcore          2016   \n",
      "3                  tedeschi trucks band             anyhow          2016   \n",
      "4  lukas nelson and promise of the real  if i started over          2017   \n",
      "\n",
      "   genre                                             lyrics      topic  \n",
      "0   rock  awake know go see time clear world mirror worl...       dark  \n",
      "1   rock  shouldn summer pretty build spill ready overfl...  lifestyle  \n",
      "2  blues  lose deep catch breath think say try break wal...    sadness  \n",
      "3  blues  run bitter taste take rest feel anchor soul pl...    sadness  \n",
      "4  blues  think think different set apart sober mind sym...       dark  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BNB     F1-macro = 0.354\n",
      "MNB     F1-macro = 0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg  F1-macro = 0.625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#initializing a sample df\n",
    "df = pd.read_csv(\"/Users/yangshuming/Downloads/dataset.tsv\", sep=\"\\t\")\n",
    "print(df.shape)          \n",
    "print(df[\"topic\"].value_counts())\n",
    "print(df.head())\n",
    "\n",
    "#create a new colunm which gathers 'artist_name, track_name, genre and lyrics' after filling Nan value into column 'doc' for table df.\n",
    "df[\"doc\"] = (\n",
    "    df[\"artist_name\"].fillna(\"\") + \" \"\n",
    "    + df[\"track_name\"].fillna(\"\") + \" \"\n",
    "    + df[\"genre\"].fillna(\"\") + \" \"\n",
    "    + df[\"lyrics\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "import re, nltk, string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "stemmer = PorterStemmer()\n",
    "stop    = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "#cleaning the dataset\n",
    "def clean(text):\n",
    "    # Keep apostrophes inside words (e.g. **rock'n'roll**)\n",
    "    text = re.sub(r\"[^\\w\\s'’\\-]\", \" \", text)      # remove every symbol except letters, numbers & apostrophes\n",
    "    text = text.lower()\n",
    "    tokens = [stemmer.stem(t) for t in text.split() if t not in stop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "X_clean = df[\"doc\"].apply(clean).values          \n",
    "y = df[\"topic\"].values\n",
    "\n",
    "# Imports you still need\n",
    "from sklearn.pipeline import make_pipeline              # <- this line is missing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "# Vectorisers (tweak max_features to your chosen N)\n",
    "vectoriser_binary  = CountVectorizer(binary=True,  max_features=10000)\n",
    "vectoriser_counts  = CountVectorizer(binary=False, max_features=10000)\n",
    "vectoriser_tfidf   = TfidfVectorizer(sublinear_tf=True, max_features=10000)\n",
    "\n",
    "# using Stratified 5-fold object rather than train_test_split\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"]\n",
    "\n",
    "# The pipelines dictionary\n",
    "pipelines = {\n",
    "    \"BNB\":    make_pipeline(vectoriser_binary, BernoulliNB()),\n",
    "    \"MNB\":    make_pipeline(vectoriser_counts, MultinomialNB(alpha=1.0)),\n",
    "    \"LogReg\": make_pipeline(vectoriser_tfidf, LogisticRegression(max_iter=500))\n",
    "}\n",
    "# Evaluate\n",
    "import numpy as np\n",
    "for name, pipe in pipelines.items():\n",
    "    scores = cross_validate(pipe, X_clean, y, cv=cv, scoring=scoring)\n",
    "    print(f\"{name:6s}  F1-macro = {scores['test_f1_macro'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5ecd5",
   "metadata": {},
   "source": [
    "2.Temprarily producing the corresponding clean function to get X_cleaner for all the set of preprocessing. Then using the same StratifiedKFold to get the score of each set. Recording all the output to df_res. Picking up the best set which gets the heighest score. Writhing the arguments of the set into BEST_PREPROC for the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5450112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yangshuming/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/yangshuming/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lower</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem</th>\n",
       "      <th>keep_'</th>\n",
       "      <th>keep-</th>\n",
       "      <th>macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MNB</td>\n",
       "      <td>False</td>\n",
       "      <td>nltk</td>\n",
       "      <td>lemma</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MNB</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>MNB</td>\n",
       "      <td>False</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MNB</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>MNB</td>\n",
       "      <td>False</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  lower  stop    stem  keep_'  keep-  macro_F1\n",
       "115   MNB  False  nltk   lemma    True  False     0.737\n",
       "35    MNB   True  nltk  porter    True  False     0.737\n",
       "107   MNB  False  nltk  porter    True  False     0.737\n",
       "33    MNB   True  nltk  porter    True   True     0.737\n",
       "105   MNB  False  nltk  porter    True   True     0.737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>lower</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem</th>\n",
       "      <th>keep_'</th>\n",
       "      <th>keep-</th>\n",
       "      <th>macro_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MNB</td>\n",
       "      <td>False</td>\n",
       "      <td>nltk</td>\n",
       "      <td>lemma</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MNB</td>\n",
       "      <td>True</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>MNB</td>\n",
       "      <td>False</td>\n",
       "      <td>nltk</td>\n",
       "      <td>porter</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNB</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>porter</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BNB</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>porter</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BNB</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>porter</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  lower  stop    stem  keep_'  keep-  macro_F1\n",
       "115   MNB  False  nltk   lemma    True  False     0.737\n",
       "35    MNB   True  nltk  porter    True  False     0.737\n",
       "107   MNB  False  nltk  porter    True  False     0.737\n",
       "12    BNB   True  none  porter   False   True     0.356\n",
       "14    BNB   True  none  porter   False  False     0.356\n",
       "84    BNB  False  none  porter   False   True     0.356"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen BEST_PREPROC → {'model': 'MNB', 'lower': False, 'stop': 'nltk', 'stem': 'lemma', \"keep_'\": True, 'keep-': False, 'macro_F1': 0.737}\n"
     ]
    }
   ],
   "source": [
    "import itertools, re, nltk, pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")    \n",
    "nltk.download(\"omw-1.4\")     \n",
    "\n",
    "\n",
    "# options of preprocessing\n",
    "stem_opts   = {\"none\": None, \"porter\": PorterStemmer(), \"lemma\": WordNetLemmatizer()}\n",
    "lower_opts  = [True, False]\n",
    "stop_lists  = {\"none\": None,\n",
    "               \"nltk\":  set(stopwords.words(\"english\")),\n",
    "               \"sklearn\": \"english\"}                 \n",
    "keep_apos   = [True, False]\n",
    "keep_hyphen = [True, False]\n",
    "\n",
    "# clean function\n",
    "def make_cleaner(lower, stop_set, stemmer, keep_ap, keep_hy):\n",
    "    regex = r\"[^\\w\\s\" + (\"'’\" if keep_ap else \"\") + (r\"\\-\" if keep_hy else \"\") + \"]\"\n",
    "    stop  = stop_set if isinstance(stop_set, set) else set()\n",
    "    def _clean(text):\n",
    "        txt = re.sub(regex, \" \", text)\n",
    "        if lower: txt = txt.lower()\n",
    "        toks = txt.split()\n",
    "        if stop: toks = [t for t in toks if t not in stop]\n",
    "        if stemmer: toks = [stemmer.stem(t) if hasattr(stemmer, \"stem\")\n",
    "                            else stemmer.lemmatize(t) for t in toks]\n",
    "        return \" \".join(toks)\n",
    "    return _clean\n",
    "\n",
    "# setting cross validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "grid_iter = itertools.product(lower_opts, stop_lists.items(),\n",
    "                              stem_opts.items(), keep_apos, keep_hyphen)\n",
    "\n",
    "for lower, (stop_name, stop_set), (stem_name, stemmer), ap, hy in grid_iter:\n",
    "    cleaner   = make_cleaner(lower, stop_set, stemmer, ap, hy)\n",
    "    X_cleaner = df[\"doc\"].apply(cleaner).values\n",
    "\n",
    "    for model_name, model in [(\"BNB\", BernoulliNB()), (\"MNB\", MultinomialNB())]:\n",
    "        vec = CountVectorizer(binary=(model_name==\"BNB\"),\n",
    "                              max_features=10000,    \n",
    "                              stop_words=(stop_set if isinstance(stop_set,str) else None))\n",
    "        pipe = make_pipeline(vec, model)\n",
    "        f1 = cross_val_score(pipe, X_cleaner, y,\n",
    "                             cv=cv, scoring=\"f1_macro\").mean()\n",
    "        results.append({\n",
    "            \"model\": model_name, \"lower\": lower, \"stop\": stop_name,\n",
    "            \"stem\": stem_name, \"keep_'\": ap, \"keep-\": hy, \"macro_F1\": round(f1,3)\n",
    "        })\n",
    "\n",
    "# evaluation\n",
    "df_res = pd.DataFrame(results).sort_values(\"macro_F1\", ascending=False)\n",
    "display(df_res.head(5)) \n",
    "# displaying the top3 of each model\n",
    "top_each = df_res.groupby(\"model\").head(3)\n",
    "display(top_each)\n",
    "\n",
    "\n",
    "# choose the set that gets the highest score, then using this set following\n",
    "best = df_res.iloc[0]\n",
    "BEST_PREPROC = best.to_dict()\n",
    "print(\"Chosen BEST_PREPROC →\", BEST_PREPROC)\n",
    "\n",
    "# define clean_best function based on BEST_PREPROC\n",
    "def build_cleaner_from_cfg(cfg):\n",
    "    lower     = cfg[\"lower\"]\n",
    "    stop_set  = stop_lists[cfg[\"stop\"]]\n",
    "    stemmer   = stem_opts[cfg[\"stem\"]]\n",
    "    keep_ap   = cfg[\"keep_'\"]\n",
    "    keep_hy   = cfg[\"keep-\"]\n",
    "    return make_cleaner(lower, stop_set, stemmer, keep_ap, keep_hy)\n",
    "\n",
    "clean_best = build_cleaner_from_cfg(BEST_PREPROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08777740",
   "metadata": {},
   "source": [
    "3.Transforming text into matrix, then evaluate each metrics for model BNB & MNB. The dataset, which rate of each type is 490 : 376 : 347 : 205 : 82, is imbalanced. So choosing Macro-F1 as the primary metric and accuracy as the secondary metric to evaluate the models. As the result, MNB is the better model for classification. MNB plus the best preprocessing will be used as the default classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "59c1880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>macroF1</th>\n",
       "      <th>wF1</th>\n",
       "      <th>macroRec</th>\n",
       "      <th>macroPrec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BNB</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNB</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc  bal_acc  macroF1    wF1  macroRec  macroPrec\n",
       "BNB  0.542    0.392    0.350  0.478     0.392      0.475\n",
       "MNB  0.802    0.711    0.737  0.795     0.711      0.824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "X = df[\"doc\"].apply(clean_best).values      \n",
    "y = df[\"topic\"].values\n",
    "\n",
    "# ② vectorizer + model\n",
    "vec_B   = CountVectorizer(binary=True,  max_features=10000)\n",
    "vec_M   = CountVectorizer(binary=False, max_features=10000)   \n",
    "\n",
    "pipe_BNB = make_pipeline(vec_B, BernoulliNB())\n",
    "pipe_MNB = make_pipeline(vec_M, MultinomialNB())\n",
    "\n",
    "# ③ 5-fold CV\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\"acc\":\"accuracy\",\n",
    "           \"bal_acc\":\"balanced_accuracy\",\n",
    "           \"macroF1\":\"f1_macro\",\n",
    "           \"wF1\":\"f1_weighted\",\n",
    "           \"macroRec\"   : \"recall_macro\",\n",
    "           \"macroPrec\"  : \"precision_macro\",}\n",
    "\n",
    "res = {}\n",
    "for name, pipe in {\"BNB\":pipe_BNB, \"MNB\":pipe_MNB}.items():\n",
    "    scores = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    res[name] = {m: scores[f\"test_{m}\"].mean() for m in scoring}\n",
    "\n",
    "df_cmp = pd.DataFrame(res).T.round(3)\n",
    "display(df_cmp)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad6330",
   "metadata": {},
   "source": [
    "4.setting several N, 100 200 300 400 500 750 and 1000, to measure which is the best N. As we can see the result, the Macro-F1 rises first then drop. So comparing all the N's, 400 is the best N for the most frequent words in the Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "fb8ecdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>BNB_macroF1</th>\n",
       "      <th>MNB_macroF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>750</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      N  BNB_macroF1  MNB_macroF1\n",
       "0   100        0.451        0.726\n",
       "1   200        0.513        0.824\n",
       "2   300        0.547        0.845\n",
       "3   400        0.562        0.853\n",
       "4   500        0.556        0.856\n",
       "5   750        0.542        0.852\n",
       "6  1000        0.529        0.836"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "# cleaning data\n",
    "X_best = df[\"doc\"].apply(clean_best).values\n",
    "y      = df[\"topic\"].values\n",
    "\n",
    "# setting N's\n",
    "N_list = [100, 200, 300, 400, 500, 750, 1000]\n",
    "\n",
    "# cross validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rows = []\n",
    "for N in N_list:\n",
    "    # BNB: binary feature\n",
    "    vec_B = CountVectorizer(binary=True,  max_features=N)\n",
    "    f1_B  = cross_val_score(make_pipeline(vec_B, BernoulliNB()),\n",
    "                            X_best, y, cv=cv, scoring=\"f1_macro\").mean()\n",
    "    # MNB: frequency feature\n",
    "    vec_M = CountVectorizer(binary=False, max_features=N)\n",
    "    f1_M  = cross_val_score(make_pipeline(vec_M, MultinomialNB()),\n",
    "                            X_best, y, cv=cv, scoring=\"f1_macro\").mean()\n",
    "    rows.append((N, round(f1_B,3), round(f1_M,3)))\n",
    "\n",
    "df_N = pd.DataFrame(rows, columns=[\"N\", \"BNB_macroF1\", \"MNB_macroF1\"])\n",
    "display(df_N)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(df_N[\"N\"], df_N[\"BNB_macroF1\"], marker=\"o\", label=\"BNB\")\n",
    "plt.plot(df_N[\"N\"], df_N[\"MNB_macroF1\"], marker=\"o\", label=\"MNB\")\n",
    "plt.xscale(\"log\"); plt.xlabel(\"Vocabulary size N (log scale)\")\n",
    "plt.ylabel(\"Macro-F1\"); plt.title(\"Effect of N on Macro-F1\")\n",
    "plt.legend(); plt.grid(True, ls=\"--\", alpha=.4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4e716",
   "metadata": {},
   "source": [
    "5.Another machine learning method that i use is linear SVM, which is a discriminative classifier. Different from the MNB and BNB, it maximizes the gap between classes, perfoming dominatively on Countvectorizer and tf-idf vector. For linear SVM i use here, preprocessing is same used for BNB and MNB, and N, which is 400, the best for MNB and BNB, is used for linear SVM as well. In additioin, i tune another hyperparameter C. i choose three value of C, for example 0.01, 0,1 and 1. Using GridSearch to select the best result of each C, then return the C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "17dfbc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best C = 0.1\n",
      "5-fold Macro-F1 = 0.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/anaconda3/envs/rs9727/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>macroF1</th>\n",
       "      <th>wF1</th>\n",
       "      <th>macroRec</th>\n",
       "      <th>macroPrec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MNB</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BNB</th>\n",
       "      <td>0.542</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         acc  bal_acc  macroF1    wF1  macroRec  macroPrec\n",
       "Model                                                     \n",
       "SVM    0.829    0.791    0.791  0.829     0.791      0.795\n",
       "MNB    0.802    0.711    0.737  0.795     0.711      0.824\n",
       "BNB    0.542    0.392    0.350  0.478     0.392      0.475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV\n",
    "\n",
    "# text → tf-idf features\n",
    "vec   = CountVectorizer(max_features=400,  \n",
    "                        stop_words=None, binary=False)\n",
    "tfidf = TfidfTransformer(sublinear_tf=True)\n",
    "\n",
    "# Linear SVM classifier\n",
    "svm   = LinearSVC(class_weight=\"balanced\", dual=False)  \n",
    "\n",
    "pipe_svm = make_pipeline(vec, tfidf, svm)\n",
    "\n",
    "# testing the best C\n",
    "param_grid = {\"linearsvc__C\": [0.01, 0.1, 1]}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe_svm, param_grid,\n",
    "                    scoring=\"f1_macro\", cv=cv, n_jobs=-1)\n",
    "grid.fit(df[\"doc\"].apply(clean_best).values, y)\n",
    "\n",
    "print(\"the best C =\", grid.best_params_[\"linearsvc__C\"])\n",
    "print(\"5-fold Macro-F1 =\", round(grid.best_score_, 3))\n",
    "\n",
    "svm_best = grid.best_estimator_ \n",
    "scoring = {\"acc\":\"accuracy\",\n",
    "           \"bal_acc\":\"balanced_accuracy\",\n",
    "           \"macroF1\":\"f1_macro\",\n",
    "           \"wF1\":\"f1_weighted\",\n",
    "           \"macroRec\"   : \"recall_macro\",\n",
    "           \"macroPrec\"  : \"precision_macro\",}\n",
    "\n",
    "models = {\n",
    "    \"BNB\" : pipe_BNB,\n",
    "    \"MNB\" : pipe_MNB,\n",
    "    \"SVM\" : svm_best, # uing the best C of SVM\n",
    "}\n",
    "\n",
    "records = []\n",
    "for name, est in models.items():\n",
    "    scores = cross_validate(est, X_best, y, cv=cv,\n",
    "                            scoring=scoring, n_jobs=-1)\n",
    "    records.append({\n",
    "        k: scores[f\"test_{k}\"].mean() for k in scoring\n",
    "    } | {\"Model\": name})\n",
    "\n",
    "df_cmp = (pd.DataFrame(records)\n",
    "            .set_index(\"Model\")\n",
    "            .round(3)\n",
    "            .sort_values(\"macroF1\", ascending=False))\n",
    "display(df_cmp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef47139c",
   "metadata": {},
   "source": [
    "Part2:\n",
    "1.Deviding the first 1000 data into training data and test data, first 750 of 1000 are training data and last 250 of 1000 are test data. predicting the topic for all the 1500 songs, training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "acaf2d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted label of all songs:\n",
      "0            dark\n",
      "1       lifestyle\n",
      "2         sadness\n",
      "3         sadness\n",
      "4            dark\n",
      "          ...    \n",
      "1495      emotion\n",
      "1496         dark\n",
      "1497         dark\n",
      "1498     personal\n",
      "1499      sadness\n",
      "Name: pred_topic, Length: 1500, dtype: object\n",
      "the predicted label of training data:\n",
      "0           dark\n",
      "1      lifestyle\n",
      "2        sadness\n",
      "3        sadness\n",
      "4           dark\n",
      "         ...    \n",
      "745     personal\n",
      "746    lifestyle\n",
      "747    lifestyle\n",
      "748      sadness\n",
      "749         dark\n",
      "Name: pred_topic, Length: 750, dtype: object\n",
      "the predicted label of test data:\n",
      "0       sadness\n",
      "1      personal\n",
      "2          dark\n",
      "3          dark\n",
      "4          dark\n",
      "         ...   \n",
      "245     sadness\n",
      "246    personal\n",
      "247     sadness\n",
      "248        dark\n",
      "249        dark\n",
      "Name: pred_topic, Length: 250, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# split the dataset. The first 750 rows are splited to train data and data from 750 to 1000 row are classified to test data\n",
    "train_df = df.iloc[:750].reset_index(drop=True)    \n",
    "test_df  = df.iloc[750:1000].reset_index(drop=True)\n",
    "\n",
    "X_clean_train = train_df[\"doc\"].apply(clean_best).values\n",
    "y_train       = train_df[\"topic\"].values\n",
    "\n",
    "# training the model\n",
    "best_clf = svm_best                      \n",
    "best_clf.fit(X_clean_train, y_train)         \n",
    "\n",
    "# getting the label of each songs\n",
    "df[\"pred_topic\"] = best_clf.predict(df[\"doc\"].apply(clean_best))\n",
    "\n",
    "train_df[\"pred_topic\"] = df.loc[:749,  \"pred_topic\"].values\n",
    "test_df [\"pred_topic\"] = df.loc[750:999, \"pred_topic\"].values\n",
    "\n",
    "print(\"the predicted label of all songs:\\n\",df[\"pred_topic\"], sep=\"\")\n",
    "print(\"the predicted label of training data:\\n\", train_df[\"pred_topic\"], sep=\"\")\n",
    "print(\"the predicted label of test data:\\n\", test_df[\"pred_topic\"], sep=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fdf72a",
   "metadata": {},
   "source": [
    "Collecting text for each topics, and fitting vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "c7fc1c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dark       songs=243  vocab= 400\n",
      "emotion    songs= 45  vocab= 400\n",
      "lifestyle  songs= 96  vocab= 400\n",
      "personal   songs=185  vocab= 400\n",
      "sadness    songs=181  vocab= 400\n"
     ]
    }
   ],
   "source": [
    "# gurantee that every data has its correct topic\n",
    "topics = [\"dark\", \"emotion\", \"lifestyle\", \"personal\", \"sadness\"]\n",
    "\n",
    "# producing fitVector for every topics. Each topic has its own vector\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "N = 400                     \n",
    "topic_vecs  = {}            # {'dark': vectorizer, ...}\n",
    "song_tfidf  = {}            # {'dark': matrix (n_doc × N), ...}\n",
    "\n",
    "for t in topics:\n",
    "    # extracting all the lyrics from training data of the topic\n",
    "    docs_t = train_df.loc[train_df[\"pred_topic\"] == t, \"doc\"].apply(clean_best).tolist()\n",
    "    if not docs_t:            \n",
    "        continue\n",
    "    \n",
    "    # vectorizer\n",
    "    vec = TfidfVectorizer(max_features=N, sublinear_tf=True)\n",
    "    X_t = vec.fit_transform(docs_t)      \n",
    "    \n",
    "    topic_vecs[t] = vec\n",
    "    song_tfidf[t] = X_t\n",
    "\n",
    "    print(f\"{t:<9s}  songs={X_t.shape[0]:3d}  vocab={len(vec.vocabulary_):4d}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf03398",
   "metadata": {},
   "source": [
    "Users liking the songs, matching the keywords of each users with the lyrics of songs to demonstrate the user like which topic songs. Reading to users profiles, user1 and user2, and creating a new user3 given topics and keywords. Searching the training dataset and fufilling the likes list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2e90e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user1 liked songs per topic:\n",
      "  dark     : 64\n",
      "  emotion  : 26\n",
      "  lifestyle: 35\n",
      "  personal : 118\n",
      "  sadness  : 10\n",
      "\n",
      "user2 liked songs per topic:\n",
      "  dark     : 0\n",
      "  emotion  : 13\n",
      "  lifestyle: 0\n",
      "  personal : 0\n",
      "  sadness  : 17\n",
      "\n",
      "user3 liked songs per topic:\n",
      "  dark     : 52\n",
      "  emotion  : 0\n",
      "  lifestyle: 18\n",
      "  personal : 33\n",
      "  sadness  : 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, re\n",
    "\n",
    "# reading the keywords of user1 and user2.\n",
    "def load_user_keywords(tsv_path):\n",
    "    \n",
    "    d = {}\n",
    "    for line in open(tsv_path, encoding=\"utf-8\"):\n",
    "        topic, kw_str = line.strip().split(\"\\t\")\n",
    "        kws = [k.strip().lower() for k in kw_str.split(\",\") if k.strip()]\n",
    "        d[topic] = kws\n",
    "    return d\n",
    "\n",
    "user_kw = {\n",
    "    \"user1\": load_user_keywords(\"/Users/yangshuming/Downloads/user1.tsv\"),\n",
    "    \"user2\": load_user_keywords(\"/Users/yangshuming/Downloads/user2.tsv\"),\n",
    "}\n",
    "\n",
    "# defining a user3 with topics and keywords\n",
    "user_kw[\"user3\"] = {\n",
    "    \"dark\"     : [\"night\", \"shadow\", \"death\"],\n",
    "    \"lifestyle\": [\"party\", \"dance\", \"money\"],\n",
    "    \"personal\" : [\"family\", \"home\"]\n",
    "    \n",
    "}\n",
    "\n",
    "# users liking songs\n",
    "\n",
    "train_df = df.iloc[:750]\n",
    "\n",
    "# initializing：{user: {topic: [doc, doc, ...]}}\n",
    "user_likes = {u:{t:[] for t in topics} for u in user_kw.keys()}\n",
    "\n",
    "pattern = re.compile(r\"[a-z']+\")   \n",
    "\n",
    "def liked(lyric, kw_list):\n",
    "    if not kw_list:\n",
    "        return False\n",
    "    words = set(pattern.findall(lyric.lower()))\n",
    "    return any(k in words for k in kw_list)\n",
    "\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    topic_pred  = row[\"pred_topic\"].lower()\n",
    "    lyric_lower = row[\"lyrics\"].lower()\n",
    "\n",
    "    for usr, kw_dict in user_kw.items():\n",
    "        if liked(lyric_lower, kw_dict.get(topic_pred, [])):\n",
    "            user_likes[usr][topic_pred].append(lyric_lower)\n",
    "\n",
    "# print the liked songs for each users\n",
    "for usr in user_likes:\n",
    "    print(f\"\\n{usr} liked songs per topic:\")\n",
    "    for t in topics:\n",
    "        print(f\"  {t:<9s}: {len(user_likes[usr][t])}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bba83",
   "metadata": {},
   "source": [
    "Integrating user_likes and topic_vecs to generate tf-idf vector of each users in every topics. TfidfVectorizer (vec) transforming text into tf-idf vector to get user profile user_profiles[user][t]. Getting top-20 words by using arr.argsort().\n",
    "\n",
    "Comment: Some words seem not reasonable. for example, the top-20 existing words of user1 for the dark topic have 'oouuu, platform, whoaohoh...', which don't represent dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "75891440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====  USER1  =====\n",
      "dark     : dilly(0.11), lanky(0.11), oouuu(0.10), gladiator(0.10), platform(0.09), slave(0.09), whoaohoh(0.09), statue(0.09), harder(0.08), slow(0.08), papa(0.08), silent(0.08), murder(0.08), riot(0.08), brother(0.08), sword(0.08), story(0.08), cry(0.07), battle(0.07), follow(0.07)\n",
      "emotion  : video(0.12), loove(0.12), vibe(0.12), touch(0.11), sunrise(0.11), gimme(0.11), vision(0.11), feelin(0.11), luck(0.10), lovin(0.10), human(0.10), morning(0.10), traffic(0.10), miss(0.09), doin(0.09), addiction(0.09), week(0.09), soft(0.09), body(0.09), coast(0.09)\n",
      "lifestyle: spoil(0.12), closer(0.12), lalala(0.11), telephone(0.11), ring(0.11), oohoohooh(0.11), depression(0.11), snake(0.10), tire(0.10), bada(0.10), charmer(0.10), backroad(0.09), ready(0.09), woah(0.09), unconditional(0.09), dear(0.09), thought(0.09), moooooove(0.09), celebrate(0.09), boom(0.09)\n",
      "personal : ordinary(0.10), shout(0.09), oohoohoohooh(0.09), automaton(0.09), crayon(0.08), habit(0.08), vibe(0.07), necessity(0.07), wicked(0.07), tooth(0.07), chemical(0.07), heartbreak(0.07), peculiar(0.07), realize(0.07), bare(0.07), wonderful(0.07), sister(0.07), thank(0.07), teach(0.07), american(0.07)\n",
      "sadness  : club(0.23), cry(0.23), steal(0.19), music(0.16), greater(0.15), smile(0.14), true(0.14), tear(0.14), mean(0.13), lift(0.13), darling(0.13), forever(0.13), blame(0.13), fire(0.12), fear(0.12), ring(0.12), baby(0.12), thousand(0.12), word(0.11), say(0.10)\n",
      "\n",
      "=====  USER2  =====\n",
      "dark     : <no liked songs>\n",
      "emotion  : video(0.16), loove(0.16), touch(0.15), sunrise(0.15), gimme(0.15), vision(0.15), luck(0.14), lovin(0.14), morning(0.13), addiction(0.13), week(0.13), body(0.12), soft(0.12), knock(0.12), laughter(0.11), fly(0.11), strong(0.11), wait(0.11), kiss(0.10), spit(0.10)\n",
      "lifestyle: <no liked songs>\n",
      "personal : <no liked songs>\n",
      "sadness  : violence(0.16), rainwater(0.16), magnify(0.14), step(0.14), icecold(0.13), ahead(0.12), crash(0.12), silence(0.11), goodbye(0.11), sing(0.11), spin(0.11), beer(0.11), blame(0.11), inside(0.11), body(0.11), wave(0.11), open(0.11), drift(0.11), smile(0.11), laughter(0.11)\n",
      "\n",
      "=====  USER3  =====\n",
      "dark     : lanky(0.12), dilly(0.12), melodiesinfonie(0.11), gladiator(0.11), untitled(0.11), wing(0.10), oooh(0.10), marijuana(0.09), needle(0.09), whisper(0.09), frame(0.09), slide(0.09), feat(0.09), travel(0.08), desperate(0.08), remix(0.08), death(0.08), follow(0.08), evil(0.08), murder(0.08)\n",
      "emotion  : <no liked songs>\n",
      "lifestyle: spoil(0.17), snake(0.14), charmer(0.13), tire(0.13), drinkin(0.13), heartache(0.13), medication(0.13), punch(0.13), unconditional(0.12), ready(0.12), moooooove(0.12), crawl(0.11), belief(0.11), flute(0.11), gonna(0.11), journey(0.11), tonight(0.10), whoa(0.10), jukebox(0.10), drink(0.10)\n",
      "personal : necessity(0.12), israelite(0.12), peculiar(0.12), bare(0.12), ironside(0.12), bore(0.11), lord(0.11), thank(0.11), softly(0.11), whoaohohoh(0.11), beat(0.11), teach(0.10), isolation(0.10), inch(0.10), return(0.09), learn(0.09), place(0.09), gotta(0.09), home(0.08), alright(0.08)\n",
      "sadness  : <no liked songs>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "user_profiles = defaultdict(dict)      \n",
    "\n",
    "for user, likes_by_topic in user_likes.items():\n",
    "    print(f\"\\n=====  {user.upper()}  =====\")\n",
    "    for t in topics:\n",
    "        docs = likes_by_topic[t]\n",
    "        if not docs:                          \n",
    "            print(f\"{t:<9s}: <no liked songs>\")\n",
    "            continue\n",
    "        \n",
    "        # merging all the lyrics of liked songs into one text \n",
    "        big_doc = \" \".join(docs)\n",
    "        \n",
    "        # reflecting to the tf-idf vector space of the topic \n",
    "        vec = topic_vecs[t]\n",
    "        tfidf_vec = vec.transform([clean_best(big_doc)])   \n",
    "        user_profiles[user][t] = tfidf_vec                 \n",
    "        \n",
    "        # getting top-20 words\n",
    "        arr = tfidf_vec.toarray().ravel()\n",
    "        top_idx = arr.argsort()[-20:][::-1]                \n",
    "        terms   = vec.get_feature_names_out()[top_idx]\n",
    "        weights = arr[top_idx]\n",
    "        \n",
    "    \n",
    "        term_list = \", \".join(f\"{w}({s:.2f})\" for w, s in zip(terms, weights))\n",
    "        print(f\"{t:<9s}: {term_list}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada94305",
   "metadata": {},
   "source": [
    "2.Selecting N=25 for the recommendation list, then generating the recommondation list according to the cosine similarity, higher score representing user likes the song more possibly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7243004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dark': (70, 400), 'emotion': (19, 400), 'lifestyle': (29, 400), 'personal': (58, 400), 'sadness': (74, 400)}\n",
      "\n",
      "=====  Top-25 for user1  =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>881</td>\n",
       "      <td>dark</td>\n",
       "      <td>alec benjamin</td>\n",
       "      <td>boy in the bubble</td>\n",
       "      <td>0.340272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>792</td>\n",
       "      <td>dark</td>\n",
       "      <td>deca</td>\n",
       "      <td>donner bell</td>\n",
       "      <td>0.338837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>789</td>\n",
       "      <td>sadness</td>\n",
       "      <td>anita baker</td>\n",
       "      <td>will you be mine</td>\n",
       "      <td>0.332036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>992</td>\n",
       "      <td>emotion</td>\n",
       "      <td>taylor swift</td>\n",
       "      <td>i did something bad</td>\n",
       "      <td>0.316069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>884</td>\n",
       "      <td>personal</td>\n",
       "      <td>alborosie</td>\n",
       "      <td>rocky road</td>\n",
       "      <td>0.311450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>901</td>\n",
       "      <td>dark</td>\n",
       "      <td>hunter hayes</td>\n",
       "      <td>still</td>\n",
       "      <td>0.303940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>855</td>\n",
       "      <td>dark</td>\n",
       "      <td>the dear hunter</td>\n",
       "      <td>the flame (is gone)</td>\n",
       "      <td>0.300484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>795</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>wallows</td>\n",
       "      <td>it's only right</td>\n",
       "      <td>0.299917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>926</td>\n",
       "      <td>personal</td>\n",
       "      <td>the band steele</td>\n",
       "      <td>sit awhile</td>\n",
       "      <td>0.294589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>897</td>\n",
       "      <td>personal</td>\n",
       "      <td>playboi carti</td>\n",
       "      <td>love hurts (feat. travis scott)</td>\n",
       "      <td>0.293744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id      topic      artist_name                       track_name  \\\n",
       "0     881       dark    alec benjamin                boy in the bubble   \n",
       "1     792       dark             deca                      donner bell   \n",
       "2     789    sadness      anita baker                 will you be mine   \n",
       "3     992    emotion     taylor swift              i did something bad   \n",
       "4     884   personal        alborosie                       rocky road   \n",
       "5     901       dark     hunter hayes                            still   \n",
       "6     855       dark  the dear hunter              the flame (is gone)   \n",
       "7     795  lifestyle          wallows                  it's only right   \n",
       "8     926   personal  the band steele                       sit awhile   \n",
       "9     897   personal    playboi carti  love hurts (feat. travis scott)   \n",
       "\n",
       "      score  \n",
       "0  0.340272  \n",
       "1  0.338837  \n",
       "2  0.332036  \n",
       "3  0.316069  \n",
       "4  0.311450  \n",
       "5  0.303940  \n",
       "6  0.300484  \n",
       "7  0.299917  \n",
       "8  0.294589  \n",
       "9  0.293744  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====  Top-25 for user2  =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802</td>\n",
       "      <td>sadness</td>\n",
       "      <td>skip marley</td>\n",
       "      <td>cry to me</td>\n",
       "      <td>0.311086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>943</td>\n",
       "      <td>sadness</td>\n",
       "      <td>naomi scott</td>\n",
       "      <td>speechless (full)</td>\n",
       "      <td>0.293870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>865</td>\n",
       "      <td>sadness</td>\n",
       "      <td>lil wayne</td>\n",
       "      <td>scared of the dark (feat. xxxtentacion)</td>\n",
       "      <td>0.271859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>766</td>\n",
       "      <td>sadness</td>\n",
       "      <td>kygo</td>\n",
       "      <td>remind me to forget</td>\n",
       "      <td>0.270693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>818</td>\n",
       "      <td>sadness</td>\n",
       "      <td>311</td>\n",
       "      <td>hey yo</td>\n",
       "      <td>0.262529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>899</td>\n",
       "      <td>emotion</td>\n",
       "      <td>parker millsap</td>\n",
       "      <td>hands up</td>\n",
       "      <td>0.260328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>868</td>\n",
       "      <td>sadness</td>\n",
       "      <td>soja</td>\n",
       "      <td>i can't stop dreaming</td>\n",
       "      <td>0.259380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>789</td>\n",
       "      <td>sadness</td>\n",
       "      <td>anita baker</td>\n",
       "      <td>will you be mine</td>\n",
       "      <td>0.256330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>791</td>\n",
       "      <td>sadness</td>\n",
       "      <td>hellyeah</td>\n",
       "      <td>love falls</td>\n",
       "      <td>0.246589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>952</td>\n",
       "      <td>sadness</td>\n",
       "      <td>jonas brothers</td>\n",
       "      <td>don't throw it away</td>\n",
       "      <td>0.246517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id    topic     artist_name                               track_name  \\\n",
       "0     802  sadness     skip marley                                cry to me   \n",
       "1     943  sadness     naomi scott                        speechless (full)   \n",
       "2     865  sadness       lil wayne  scared of the dark (feat. xxxtentacion)   \n",
       "3     766  sadness            kygo                      remind me to forget   \n",
       "4     818  sadness             311                                   hey yo   \n",
       "5     899  emotion  parker millsap                                 hands up   \n",
       "6     868  sadness            soja                    i can't stop dreaming   \n",
       "7     789  sadness     anita baker                         will you be mine   \n",
       "8     791  sadness        hellyeah                               love falls   \n",
       "9     952  sadness  jonas brothers                      don't throw it away   \n",
       "\n",
       "      score  \n",
       "0  0.311086  \n",
       "1  0.293870  \n",
       "2  0.271859  \n",
       "3  0.270693  \n",
       "4  0.262529  \n",
       "5  0.260328  \n",
       "6  0.259380  \n",
       "7  0.256330  \n",
       "8  0.246589  \n",
       "9  0.246517  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====  Top-25 for user3  =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>884</td>\n",
       "      <td>personal</td>\n",
       "      <td>alborosie</td>\n",
       "      <td>rocky road</td>\n",
       "      <td>0.339611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>926</td>\n",
       "      <td>personal</td>\n",
       "      <td>the band steele</td>\n",
       "      <td>sit awhile</td>\n",
       "      <td>0.328652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>792</td>\n",
       "      <td>dark</td>\n",
       "      <td>deca</td>\n",
       "      <td>donner bell</td>\n",
       "      <td>0.322562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901</td>\n",
       "      <td>dark</td>\n",
       "      <td>hunter hayes</td>\n",
       "      <td>still</td>\n",
       "      <td>0.321354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>944</td>\n",
       "      <td>personal</td>\n",
       "      <td>timeflies</td>\n",
       "      <td>once in a while</td>\n",
       "      <td>0.312705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>797</td>\n",
       "      <td>personal</td>\n",
       "      <td>billie eilish</td>\n",
       "      <td>bored</td>\n",
       "      <td>0.312659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>984</td>\n",
       "      <td>dark</td>\n",
       "      <td>busta rhymes</td>\n",
       "      <td>why we die (feat. dmx and jay z)</td>\n",
       "      <td>0.305355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>881</td>\n",
       "      <td>dark</td>\n",
       "      <td>alec benjamin</td>\n",
       "      <td>boy in the bubble</td>\n",
       "      <td>0.305321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>765</td>\n",
       "      <td>personal</td>\n",
       "      <td>iya terra</td>\n",
       "      <td>follow your heart (feat. zion thompson from th...</td>\n",
       "      <td>0.297358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>923</td>\n",
       "      <td>personal</td>\n",
       "      <td>soja</td>\n",
       "      <td>everything to me</td>\n",
       "      <td>0.290564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id     topic      artist_name  \\\n",
       "0     884  personal        alborosie   \n",
       "1     926  personal  the band steele   \n",
       "2     792      dark             deca   \n",
       "3     901      dark     hunter hayes   \n",
       "4     944  personal        timeflies   \n",
       "5     797  personal    billie eilish   \n",
       "6     984      dark     busta rhymes   \n",
       "7     881      dark    alec benjamin   \n",
       "8     765  personal        iya terra   \n",
       "9     923  personal             soja   \n",
       "\n",
       "                                          track_name     score  \n",
       "0                                         rocky road  0.339611  \n",
       "1                                         sit awhile  0.328652  \n",
       "2                                        donner bell  0.322562  \n",
       "3                                              still  0.321354  \n",
       "4                                    once in a while  0.312705  \n",
       "5                                              bored  0.312659  \n",
       "6                   why we die (feat. dmx and jay z)  0.305355  \n",
       "7                                  boy in the bubble  0.305321  \n",
       "8  follow your heart (feat. zion thompson from th...  0.297358  \n",
       "9                                   everything to me  0.290564  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "N_RECOMMEND = 25                               \n",
    "users       = [\"user1\", \"user2\", \"user3\"]      \n",
    "topics      = [\"dark\", \"emotion\", \"lifestyle\", \"personal\", \"sadness\"]\n",
    "\n",
    "\n",
    "test_df = df.iloc[750:1000].copy().reset_index()   \n",
    "test_df.rename(columns={\"index\": \"row_id\"}, inplace=True)\n",
    "\n",
    "# generating tf-idf vector of Week-4 songs for each topics\n",
    "song_tfidf_test = {}       \n",
    "song_meta_test  = {}       \n",
    "\n",
    "for t in topics:\n",
    "    mask = test_df[\"pred_topic\"] == t           \n",
    "    docs = test_df.loc[mask, \"doc\"].apply(clean_best).tolist()\n",
    "    if not docs:                                \n",
    "        continue\n",
    "    vec = topic_vecs[t]                        \n",
    "    X   = vec.transform(docs)                   \n",
    "    song_tfidf_test[t] = X\n",
    "    song_meta_test[t] = test_df.loc[mask, [\"row_id\", \"artist_name\", \"track_name\"]]\\\n",
    "                                      .reset_index(drop=True)\n",
    "\n",
    "print({k: m.shape for k, m in song_tfidf_test.items()})\n",
    "\n",
    "\n",
    "\n",
    "# calculating the score of all the songs of week-4 for every users\n",
    "recomm_all = {}          \n",
    "\n",
    "for u in users:\n",
    "    rows = []            \n",
    "    \n",
    "    for t in topics:\n",
    "        \n",
    "        user_vec = user_profiles[u].get(t)\n",
    "        if user_vec is None or user_vec.nnz == 0:\n",
    "            continue\n",
    "        \n",
    "        song_mat = song_tfidf_test.get(t)\n",
    "        if song_mat is None or song_mat.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        # calculating the cosine similarity\n",
    "        sims = cosine_similarity(song_mat, user_vec).ravel()\n",
    "        \n",
    "        meta_df = song_meta_test[t].copy()\n",
    "        meta_df[\"topic\"] = t\n",
    "        meta_df[\"score\"] = sims\n",
    "        rows.append(meta_df)\n",
    "    \n",
    "\n",
    "    if rows:\n",
    "        full_df = pd.concat(rows, ignore_index=True)\n",
    "        recomm_all[u] = full_df.sort_values(\"score\", ascending=False)\\\n",
    "                               .head(N_RECOMMEND)\\\n",
    "                               .reset_index(drop=True)\n",
    "    else:\n",
    "        recomm_all[u] = pd.DataFrame()   \n",
    "\n",
    "\n",
    "for u, rec in recomm_all.items():\n",
    "    print(f\"\\n=====  Top-{N_RECOMMEND} for {u}  =====\")\n",
    "    if rec.empty:\n",
    "        print(\" <no recommendation>\")\n",
    "    else:\n",
    "        display(rec[[\"row_id\", \"topic\", \"artist_name\", \"track_name\", \"score\"]].head(10))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef04db9",
   "metadata": {},
   "source": [
    "producing the truth label, using the pattern of keywords + predicted topics to discriminate the song is liked, while the keywords matching the lyrics of the song, or disliked, and put the result in truth_df, which is a table including all the songs from week-4 liked or disliked by each users. Then defining an estimation function merging the recommadation result and truth_df to calculate Precision/Recall/F1@N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f6be5305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "user1    83\n",
      "user2    11\n",
      "user3    31\n",
      "Name: liked, dtype: int64\n",
      "    user  P@25   R@25  F1@25\n",
      "0  user1  0.64  0.193  0.296\n",
      "1  user2  0.24  0.545  0.333\n",
      "2  user3  0.44  0.355  0.393\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for user in users:\n",
    "    for _, row in test_df.iterrows():          \n",
    "        pred_t   = row[\"pred_topic\"]\n",
    "        kw_list  = user_kw[user].get(pred_t, [])   \n",
    "        liked    = int(is_liked(row[\"lyrics\"], kw_list))\n",
    "\n",
    "        records.append({\n",
    "            \"row_id\": row[\"row_id\"],   \n",
    "            \"user\"  : user,\n",
    "            \"liked\" : liked\n",
    "        })\n",
    "\n",
    "truth_df = pd.DataFrame(records)\n",
    "tdf = truth_df.groupby(\"user\")[\"liked\"].sum()\n",
    "print(tdf)\n",
    "\n",
    "def metrics_at_N(recommend_df, truth_subset, N=25):\n",
    "    \n",
    "    merged = (recommend_df[[\"row_id\"]]               \n",
    "                .merge(truth_subset, on=\"row_id\", how=\"left\")\n",
    "                .fillna({\"liked\":0}))\n",
    "    hit      = int(merged[\"liked\"].sum())            \n",
    "    precision= hit / N\n",
    "    total_like = int(truth_subset[\"liked\"].sum())\n",
    "    recall   = hit / total_like if total_like else 0\n",
    "    f1       = 0 if precision+recall==0 else 2*precision*recall/(precision+recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "rows = []\n",
    "for u in users:\n",
    "    p,r,f1 = metrics_at_N(recomm_all[u], truth_df[truth_df[\"user\"]==u])\n",
    "    rows.append({\"user\":u, \"P@25\":round(p,3),\n",
    "                          \"R@25\":round(r,3),\n",
    "                          \"F1@25\":round(f1,3)})\n",
    "print(pd.DataFrame(rows))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a5ca1",
   "metadata": {},
   "source": [
    "Comparing hyperparameters. We have argument M, the number of words in the user profile for each topic, matching algorithm, cosine similarity and dot, and fixed N. As the result shows below, M = 50, which means each topic remains top 50 words, with cosine similarity gets the highest average F1@25 which equals to 0.371 . In addition, the combination of M=50 with cosine similarity keeps other metrics in an appropriate scale, so choosing it as the default matching strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a196a894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">P@25</th>\n",
       "      <th colspan=\"3\" halign=\"left\">R@25</th>\n",
       "      <th colspan=\"3\" halign=\"left\">F1@25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <th>matcher</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">010</th>\n",
       "      <th>cosine</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dot</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">020</th>\n",
       "      <th>cosine</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dot</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>030</th>\n",
       "      <th>cosine</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <th>dot</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">380</th>\n",
       "      <th>cosine</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dot</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">All</th>\n",
       "      <th>cosine</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dot</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             P@25               R@25                F1@25              \n",
       "user        user1 user2 user3  user1  user2  user3  user1  user2  user3\n",
       "M   matcher                                                            \n",
       "010 cosine   0.40  0.32  0.28  0.120  0.727  0.226  0.185  0.444  0.250\n",
       "    dot      0.32  0.32  0.28  0.096  0.727  0.226  0.148  0.444  0.250\n",
       "020 cosine   0.32  0.20  0.44  0.096  0.455  0.355  0.148  0.278  0.393\n",
       "    dot      0.28  0.20  0.40  0.084  0.455  0.323  0.130  0.278  0.357\n",
       "030 cosine   0.32  0.24  0.36  0.096  0.545  0.290  0.148  0.333  0.321\n",
       "...           ...   ...   ...    ...    ...    ...    ...    ...    ...\n",
       "370 dot      0.64  0.24  0.44  0.193  0.545  0.355  0.296  0.333  0.393\n",
       "380 cosine   0.64  0.24  0.44  0.193  0.545  0.355  0.296  0.333  0.393\n",
       "    dot      0.64  0.24  0.44  0.193  0.545  0.355  0.296  0.333  0.393\n",
       "All cosine   0.64  0.24  0.44  0.193  0.545  0.355  0.296  0.333  0.393\n",
       "    dot      0.64  0.24  0.44  0.193  0.545  0.355  0.296  0.333  0.393\n",
       "\n",
       "[78 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M    matcher\n",
      "050  cosine     0.370667\n",
      "310  dot        0.352667\n",
      "300  dot        0.346667\n",
      "All  dot        0.340667\n",
      "360  dot        0.340667\n",
      "                  ...   \n",
      "100  dot        0.254667\n",
      "170  dot        0.254667\n",
      "140  dot        0.254333\n",
      "110  dot        0.248333\n",
      "160  dot        0.236667\n",
      "Name: macroF1, Length: 78, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def truncate_vec(vec, topM: int | None):\n",
    "    if topM is None:          \n",
    "        return vec\n",
    "    if vec.nnz == 0:          \n",
    "        return vec\n",
    "    \n",
    "    arr = vec.toarray().ravel()\n",
    "    if vec.nnz <= topM:\n",
    "        return vec\n",
    "    # getting index of topM which have the higher weight\n",
    "    top_idx = arr.argsort()[-topM:]\n",
    "    mask = np.zeros_like(arr); mask[top_idx] = 1\n",
    "    arr = arr * mask          \n",
    "    return csr_matrix(arr)    \n",
    "\n",
    "# dot score\n",
    "def dot_score(song_mat, user_vec):\n",
    "    return (song_mat @ user_vec.T).toarray().ravel()      \n",
    "\n",
    "\n",
    "def metrics_at_N(recommend_df, truth_subset, N):\n",
    "    merged = (recommend_df[[\"row_id\"]]\n",
    "                .merge(truth_subset, on=\"row_id\", how=\"left\")\n",
    "                .fillna({\"liked\":0}))\n",
    "    hit = merged[\"liked\"].sum()\n",
    "    precision = hit / N\n",
    "    total_like = truth_subset[\"liked\"].sum()\n",
    "    recall = hit / total_like if total_like else 0\n",
    "    f1 = 0 if precision+recall==0 else 2*precision*recall/(precision+recall)\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "max_nnz = max(vec.nnz for u in user_profiles.values() for vec in u.values())\n",
    "# testing different M to illustrate which value of M has the best output\n",
    "M_options = {f\"{m:03d}\": m for m in range(10, max_nnz + 1, 10)}\n",
    "M_options[\"All\"] = None     \n",
    "matchers    = {\"cosine\": cosine_similarity, \"dot\": dot_score}\n",
    "N_RECOMMEND = 25\n",
    "\n",
    "rows = []\n",
    "\n",
    "for M_name, topM in M_options.items():\n",
    "    \n",
    "    user_prof_M = {}\n",
    "    for u in users:\n",
    "        d = {}\n",
    "        for t, vec in user_profiles[u].items():\n",
    "            d[t] = truncate_vec(vec, topM)\n",
    "        user_prof_M[u] = d\n",
    "    \n",
    "    for matcher_name, scorer in matchers.items():\n",
    "        # generating recommendation list\n",
    "        recomm_all_tmp = {}\n",
    "        for u in users:\n",
    "            basket = []\n",
    "            for t in topics:\n",
    "                u_vec = user_prof_M[u].get(t)\n",
    "                S_mat = song_tfidf_test.get(t)\n",
    "                if u_vec is None or u_vec.nnz == 0 or S_mat is None:\n",
    "                    continue\n",
    "                sims = (scorer(S_mat, u_vec).ravel()\n",
    "                        if matcher_name==\"cosine\"\n",
    "                        else dot_score(S_mat, u_vec))\n",
    "                tmp = song_meta_test[t].copy()\n",
    "                tmp[\"score\"] = sims; tmp[\"topic\"]=t\n",
    "                basket.append(tmp)\n",
    "            if basket:\n",
    "                df_top = (pd.concat(basket, ignore_index=True)\n",
    "                            .sort_values(\"score\", ascending=False)\n",
    "                            .head(N_RECOMMEND))\n",
    "                recomm_all_tmp[u] = df_top\n",
    "            else:\n",
    "                recomm_all_tmp[u] = pd.DataFrame()\n",
    "        \n",
    "        # evaluating\n",
    "        for u in users:\n",
    "            P,R,F1 = metrics_at_N(recomm_all_tmp[u],\n",
    "                                  truth_df[truth_df[\"user\"]==u],\n",
    "                                  N_RECOMMEND)\n",
    "            rows.append({\"user\":u, \"M\":M_name, \"matcher\":matcher_name,\n",
    "                         \"P@25\":round(P,3), \"R@25\":round(R,3), \"F1@25\":round(F1,3)})\n",
    "\n",
    "df_cmp = (pd.DataFrame(rows)\n",
    "            .set_index([\"M\",\"matcher\",\"user\"])\n",
    "            .unstack(\"user\")               \n",
    "            .round(3))\n",
    "\n",
    "display(df_cmp)\n",
    "\n",
    "f1_cols = df_cmp['F1@25']          \n",
    "# calculating the average of F1\n",
    "df_cmp = df_cmp.copy()          \n",
    "df_cmp['macroF1'] = f1_cols.mean(axis=1)\n",
    "# macroF1 descend\n",
    "print(df_cmp['macroF1'].sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72325ca1",
   "metadata": {},
   "source": [
    "Part3: for week1, 2 and 3, randomly selecting 25 songs of each week to the user, then let they mark \"y\" representing like the song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f48d9d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved：user_study_batches/Week1.csv\n",
      "file saved：user_study_batches/Week2.csv\n",
      "file saved：user_study_batches/Week3.csv\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "N = 25                                              \n",
    "random.seed(42)                                     \n",
    "\n",
    "df = df.copy()                 \n",
    "df[\"row_id\"] = df.index        \n",
    "\n",
    "# Week1-3\n",
    "week_ranges = {\"Week1\": (0, 250), \"Week2\": (250, 500), \"Week3\": (500, 750)}\n",
    "\n",
    "out_dir = Path(\"user_study_batches\"); out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "batch_info = {}                                    \n",
    "def export_batch_with_like(df_batch: pd.DataFrame, path: str):\n",
    "    out = df_batch.copy()\n",
    "    out[\"Like\"] = \"\"           \n",
    "    out.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"file saved：{path}\")\n",
    "\n",
    "for wk, (start, end) in week_ranges.items():\n",
    "    batch_df = (df.iloc[start:end]\n",
    "                  .sample(N, random_state=start)\n",
    "                  [[\"row_id\",\"artist_name\",\"track_name\"]])\n",
    "    export_batch_with_like(batch_df, out_dir / f\"{wk}.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e85ee",
   "metadata": {},
   "source": [
    "reading the three files of three weeks songs marked like. priting the total count of liked songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "db1f76cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the user likes 27 songs\n"
     ]
    }
   ],
   "source": [
    "def read_likes(csv_path):\n",
    "    tbl = pd.read_csv(csv_path)\n",
    "    liked_idx = tbl.loc[tbl[\"Like\"].astype(str).str.upper().str.startswith(\"Y\"), \"row_id\"]\n",
    "    return liked_idx.tolist()\n",
    "\n",
    "likes_idx = []\n",
    "for wk in week_ranges:\n",
    "    likes_idx.extend(read_likes(out_dir / f\"/Users/yangshuming/user_study_batches/{wk}.csv\"))\n",
    "\n",
    "print(f\"the user likes {len(likes_idx)} songs\")\n",
    "\n",
    "\n",
    "global_tfidf = TfidfVectorizer(sublinear_tf=True, max_features=400)\n",
    "global_tfidf.fit(df[\"doc\"].apply(clean_best))\n",
    "def build_profile_from_idx(idx_list):\n",
    "    lyrics_concat = \" \".join(df.loc[idx_list, \"lyrics\"].apply(clean_best))\n",
    "    vec   = global_tfidf  \n",
    "    tfidf = vec.transform([lyrics_concat])\n",
    "    return truncate_vec(tfidf, 50)                  \n",
    "\n",
    "user_profile_real = build_profile_from_idx(likes_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5784703",
   "metadata": {},
   "source": [
    "recommanding songs from week4 to user, based on the songs that user likes from training data week1-3. and let user mark the songs that they like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ece89de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Week-4 recommendation list saved as Week4recommend.csv\n"
     ]
    }
   ],
   "source": [
    "week4_df = df.iloc[750:1000].copy().reset_index()      \n",
    "X_week4   = global_tfidf.transform(week4_df[\"doc\"].apply(clean_best))\n",
    "week4_meta = week4_df[[\"row_id\",\"artist_name\",\"track_name\"]]\n",
    "\n",
    "def recommend_week4(profile_vec, topN=25):\n",
    "    sim = cosine_similarity(X_week4, profile_vec).ravel()\n",
    "    return (week4_meta.assign(score=sim)          \n",
    "                     .sort_values(\"score\", ascending=False)\n",
    "                     .head(topN)\n",
    "                     .reset_index(drop=True))\n",
    "\n",
    "N = 25\n",
    "recs = recommend_week4(user_profile_real, N)\n",
    "recs[\"Like\"] = \"\"                                 \n",
    "cols = [\"row_id\",\"artist_name\",\"track_name\",\"score\",\"Like\"]\n",
    "recs.to_csv(out_dir / \"Week4recommend.csv\",\n",
    "            columns=cols, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\" Week-4 recommendation list saved as Week4recommend.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41567dbc",
   "metadata": {},
   "source": [
    "read the file of Week4recommend, counting the songs are liked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "74555580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user likes 13 songs in 25 that are recommended。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fb4 = pd.read_csv(\"/Users/yangshuming/user_study_batches/Week4recommend.csv\")\n",
    "\n",
    "liked_mask = (\n",
    "    fb4[\"Like\"]\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.startswith(\"y\")\n",
    ")\n",
    "\n",
    "liked_count = liked_mask.sum()\n",
    "print(f\"user likes {liked_count} songs in 25 that are recommended。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rs9727",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
