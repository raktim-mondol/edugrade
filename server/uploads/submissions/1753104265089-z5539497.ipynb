{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTRS7PGvMA46"
      },
      "source": [
        "# COMP9727 Assignment 1\n",
        "WenquWang z5539497"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jcTWg8pMmtt"
      },
      "source": [
        "# Part 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgcfWEc7UN-Z"
      },
      "source": [
        "\n",
        "### basic setups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FZMNyA6JUedo",
        "outputId": "134b5632-cbd2-4d36-9a61-5a6a57e78372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# read files from GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "master_path = '/content/drive/MyDrive/COMP9727/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvuTEdggUK52"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bx9v4exsW02l",
        "outputId": "f8bb0cd0-fd88-448b-d73d-cb9c58287f92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df = pd.read_csv(master_path + 'dataset.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol86909hPf3V"
      },
      "source": [
        "Preprocess as in tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_lRXLGPCV2",
        "outputId": "35df87cb-51b9-4040-fd52-349e9351568b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                             artist_name                                               track_name  release_date    genre  \\\n",
            "0                                 loving                                        the not real lake          2016     rock   \n",
            "1                                incubus                                          into the summer          2019     rock   \n",
            "2                              reignwolf                                                 hardcore          2016    blues   \n",
            "3                   tedeschi trucks band                                                   anyhow          2016    blues   \n",
            "4   lukas nelson and promise of the real                                        if i started over          2017    blues   \n",
            "5                                tia ray                                             just my luck          2018     jazz   \n",
            "6                             rebelution                                                trap door          2018   reggae   \n",
            "7                    thank you scientist                          the amateur arsonist's handbook          2016     jazz   \n",
            "8                             zayde w√∏lf                                                gladiator          2018     rock   \n",
            "9                         eli young band                                               never land          2017  country   \n",
            "10                                  klim                                               ninetofive          2018     jazz   \n",
            "11                          terror squad  rudeboy salute (feat. buju banton, big pun and fat joe)          2017  hip hop   \n",
            "12                devin townsend project                                                    truth          2016     jazz   \n",
            "13                       vampire weekend                                         unbearably white          2019     rock   \n",
            "14                                khalid                                                   winter          2017      pop   \n",
            "15                       rend collective                                  counting every blessing          2018     rock   \n",
            "16                           post malone                          spoil my night (feat. swae lee)          2018      pop   \n",
            "17                   albert hammond, jr.                                       rocky's late night          2018    blues   \n",
            "18                    the record company                                            feels so good          2016    blues   \n",
            "19                                  kygo                                           stole the show          2016      pop   \n",
            "\n",
            "                                                                                                                                                                                                                                             lyrics      topic  \n",
            "0              awake know go see time clear world mirror world mirror magic hour confuse power steal word unheard unheard certain forget bless angry weather head angry weather head angry weather head know gentle night mindless fight walk woods       dark  \n",
            "1   shouldn summer pretty build spill ready overflow piss moan ash guess smite leave remember call forever shouldn summer summer like coil vine break crack wall fruit distil step line remember call forever shouldn summer remember call forev...  lifestyle  \n",
            "2   lose deep catch breath think say try break wall mama leave hardcore hardcore think brother say lock bedroom sister say throw away world stop hell think say try break wall think hardcore hardcore think time think like anymore try break w...    sadness  \n",
            "3   run bitter taste take rest feel anchor soul play game rule learn lessons get choose turn walk away walk away anytime anytime wake feel adrift piece miss realize push follow lose place deal wreckage soul turn walk away walk away anytime ...    sadness  \n",
            "4   think think different set apart sober mind sympathetic hearts swear oath swear oath know life play play distance great height sure kill innocents build drop death longer human be longer people target screen real drop death tell send sen...       dark  \n",
            "5   yeah happen real drink drink turn shots lose count kind luck know friends house sound silly sound stupid sentence break word get fluid listen stop ahead fool past minutes yell phone middle beg kiss luck machine luck pick luck remember m...    emotion  \n",
            "6      long long road occur look shortcut wanna cause scene wanna close okay outspoken look trap door sneak grind floor careful wish need answer head time solve problems scream perfect expect human look trap door sneak grind floor careful wish       dark  \n",
            "7   quick think good true worst best things forever pessimist drag complicate feel fear tell reason nice slow tell tell reason reason yeah hell understand lose win hand burn walk away hand satisfy notion break justify evidence lose things p...       dark  \n",
            "8   start climb face army vipers lions reach cause time tear kingdom liars jail heart pessimists nail mouth impressionists spend money therapist couldn accept gladiator gladiator gladiator pick fight gods giant slayer boneshaker dominator f...       dark  \n",
            "9   word yeah wreck roll lips high good get bottle right right wanna feet cold hard floor kiss steal wanna steal right palm hand fall fall like land head heartbeat hit feel like gravity exist wanna stop know fall fall like land hang like da...    sadness  \n",
            "10  nice place think sky separate nice surprise know life like bring life help gentle kiss good night innocence pray humble amaze beautiful little miracle life gift think live life live bring life help simple kiss good night innocence crave...   personal  \n",
            "11  grain sand weak blood stain try bottomless hourglass board piece pawn try reach eighth rank sacrifice kings queen field sorrow lose life stand right leave field sorrow grave wife stand right rest wild roses wasteland defy desert throw g...       dark  \n",
            "12                                                                                                                                    warn money money money money hallelujah hallelujah yeah hello learn live fear peace beauty unfold change home   personal  \n",
            "13  baby pull away unbearably buff mountain sight snow peak unbearably white city freeze elegant flow wind doorway unbearably cold walk bedroom write notebook unbearably white avalanche come cover eye think want surprise hard body hard mind...       dark  \n",
            "14  lose heart nighttime leave cold leave break weary drink lie tell fell morning get cold life lonely city paso days harder november grow colder winter things remember promise promise promise grow colder winter promise lose mind leave quic...   personal  \n",
            "15  blind see colour dead live forever fail redeemer bless measure lose father change ruin treasure give future bless measure count bless count bless let trust count bless count bless surely season good oooh good oooh good valley shadow dep...   personal  \n",
            "16  come spoil night feelin come play thinkin happen time spoil night spoil night spoil night night spoil night spoil night necklace natural glow dancin strobe  spoil night spoil night spend cash lose toxic take robe yeah couldn drop plenty...  lifestyle  \n",
            "17  darker longer right fear tonight decide everybody feel alright mistake tonight leave companion enjoy polite leave strand confront right emptiness wasn take doubletime perfection break leave rearrange pretty tell  inside think round drin...    sadness  \n",
            "18  wanna right today lookin wanna right today tire bein stun somethin control control control taste lips want want want come feel good feel good feel good doin want know shouldn feel good feel good feel good doin want know shouldn turn gre...    emotion  \n",
            "19  darling darling turn light watch watch credit roll cry cry know play house house heroes villains blame wilt roses stage thrill thrill go debut masterpiece curtain hold applause wave crowd final time steal steal steal steal steal steal d...    sadness  \n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.width', 280)\n",
        "pd.set_option('display.max_colwidth', 240)\n",
        "print(df.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jx0UinTBPV_o",
        "outputId": "57f335a1-3a8b-4a1d-be51-c28a4b527313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1480 entries, 0 to 1499\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   artist_name   1480 non-null   object\n",
            " 1   track_name    1480 non-null   object\n",
            " 2   release_date  1480 non-null   int64 \n",
            " 3   genre         1480 non-null   object\n",
            " 4   lyrics        1480 non-null   object\n",
            " 5   topic         1480 non-null   object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 80.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Drop duplicates and missing values\n",
        "df = df.drop_duplicates()\n",
        "df = df.dropna()\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2vwQM8FPj0m"
      },
      "source": [
        "## TEST\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "qSE-UqAZL29U"
      },
      "outputs": [],
      "source": [
        "def clean_text(txt):\n",
        "  txt = txt.lower()\n",
        "  txt = re.sub(r\"[^a-z0-9'/\\s]\", \" \", txt) #no longer removes / ' and numbers\n",
        "  tokens = txt.split()\n",
        "  return \" \".join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC3pIQ8xS6_e",
        "outputId": "53d88250-9566-4a52-f5fb-87f71e5d2b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i'm aaa aaa space mid 6 spaces 24/7\n"
          ]
        }
      ],
      "source": [
        "print(clean_text(\"I'm aaa AAA !!! !@#$%^&*() space   mId   6 spaces 24/7\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8d8htb-T38P"
      },
      "source": [
        "## Q1+Q2+Q3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLIpgUR01VZc",
        "outputId": "1bdb2884-2458-4047-e050-f7cb5f792f1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer, Binarizer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, ParameterGrid, cross_validate\n",
        "from nltk.corpus import stopwords as nltk_stop\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stemmer    = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yZz5nXWZ7L8"
      },
      "source": [
        "Q1.1 trying different clean pattern: keep numbers and symbol ' / ; keep only numbers; keep more symbols\n",
        "\n",
        "Keep ' and / because there might be I'm, he's existing in lyrics, / for 24/7 or 1/3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "AVis6mGvZ4Hr"
      },
      "outputs": [],
      "source": [
        "clean_patterns = {\n",
        "  \"less_symbol\": r\"[^a-z0-9'/\\s]\",\n",
        "  \"default\": r\"[^a-z0-9\\s]\",\n",
        "  \"more_symbol\": r\"[^a-z0-9'/#@\\s]\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaY2g-j4BNXh"
      },
      "source": [
        "Q2 Build a function generator to generate analyze function depending on params: wether do lower case, which clean pattern, which tokenize mode (stemmer or lemmatizer), which stop word filtering, ngram length (unigram and bigram). Analyze function is later used in grid search, trying to find best combination of params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "zBNzfJ66M8Rc"
      },
      "outputs": [],
      "source": [
        "def make_analyzer(lower: bool, pattern: str, tok_mode: str, stop_option: str or None, ngram_range: tuple):\n",
        "  # selection of stop words\n",
        "  if stop_option == \"sklearn\":\n",
        "    raw_stop = __import__('sklearn').feature_extraction.text.ENGLISH_STOP_WORDS\n",
        "  elif stop_option == \"nltk\":\n",
        "    raw_stop = set(nltk_stop.words(\"english\"))\n",
        "  else:\n",
        "    raw_stop = None\n",
        "\n",
        "  # if using stop words, do the same pre process (cleaning) as text\n",
        "  if raw_stop is not None:\n",
        "    processed_stop = set()\n",
        "    for sw in raw_stop:\n",
        "      txt = sw.lower() if lower else sw\n",
        "      txt = re.sub(clean_patterns[pattern], \" \", txt)\n",
        "      toks = txt.split()\n",
        "      # select by tokenize param\n",
        "      if tok_mode == \"stem\":\n",
        "        toks = [stemmer.stem(w) for w in toks]\n",
        "      elif tok_mode == \"lemma\":\n",
        "        toks = [lemmatizer.lemmatize(w) for w in toks]\n",
        "      processed_stop.update(toks)\n",
        "  else:\n",
        "    processed_stop = None\n",
        "\n",
        "  # actual cleaning and tokenization.\n",
        "  def analyzer(doc: str):\n",
        "    # wether do lowercase (nolonger needed)\n",
        "    # txt = doc.lower() if lower else doc\n",
        "    txt = doc\n",
        "    txt = re.sub(clean_patterns[pattern], \" \", txt)\n",
        "    # do basic split(global)\n",
        "    tokens = txt.split()\n",
        "    # stem/lemma\n",
        "    if tok_mode == \"stem\":\n",
        "      tokens = [stemmer.stem(w) for w in tokens]\n",
        "    elif tok_mode == \"lemma\":\n",
        "      tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    # stop word filter\n",
        "    if processed_stop is not None:\n",
        "      tokens = [w for w in tokens if w not in processed_stop]\n",
        "    # n-gram\n",
        "    min_n, max_n = ngram_range\n",
        "    if max_n == 1:\n",
        "      return tokens\n",
        "    out = []\n",
        "    L = len(tokens)\n",
        "    for n in range(min_n, max_n+1):\n",
        "      for i in range(L-n+1):\n",
        "        out.append(\" \".join(tokens[i:i+n]))\n",
        "    return out\n",
        "\n",
        "  return analyzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zP9o6z0NA8S"
      },
      "source": [
        "Building pipeline for grid search,initialize vectorizer and pass all necessary params to analyzer closure (to generate results under diferent parameter combinations). All process in vectorizer must be explicitly set to false or none, otherwise will cause warning:\n",
        "\n",
        "Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', ..........] not in stop_words.\n",
        "\n",
        "Which actually over tokenized stop word list(? not sure) and will affect result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "HaHiXAFfNAVq"
      },
      "outputs": [],
      "source": [
        "def build_pipeline(clf, clean_pattern=\"default\", lower=True, stop_option=None, ngram=(1,1), tok_mode=\"none\"):\n",
        "  vect = CountVectorizer(\n",
        "    analyzer=make_analyzer(lower, clean_pattern, tok_mode, stop_option, ngram),\n",
        "    lowercase=False, # all set to none, process by analyzer\n",
        "    preprocessor=None,\n",
        "    tokenizer=None,\n",
        "    token_pattern=None\n",
        "  )\n",
        "  steps = [(\"vect\", vect)]\n",
        "  if isinstance(clf, BernoulliNB): # add binarizer if BNB\n",
        "    steps.append((\"bin\", Binarizer(copy=False)))\n",
        "  steps.append((\"clf\", clf)) # mnb & bnb\n",
        "  return Pipeline(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-NmsD5tpMu3"
      },
      "source": [
        "Q2 Building param grid for grid search, trying all possible param combinations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "W1GcA5S2pLLf"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "  \"clean_pattern\": list(clean_patterns.keys()),\n",
        "  \"lower\": [True, False], # actually not needed here, basically no uppercase letters in dataset, keeping in case of bugs\n",
        "  \"stop_option\": [None, \"sklearn\", \"nltk\"],\n",
        "  \"ngram\": [(1,1), (1,2)],\n",
        "  \"tok_mode\": [\"none\", \"stem\", \"lemma\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVOC9XL97xQb"
      },
      "source": [
        "Q1.2 using five fold cross validate\n",
        "\n",
        "removed date from text col for it's basically irrevalent. keep the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "9UEtBqh68Fp_"
      },
      "outputs": [],
      "source": [
        "text_cols = [\"artist_name\", \"track_name\", \"genre\", \"lyrics\"]\n",
        "df[\"all_text\"] = (df[text_cols].fillna(\"\").agg(\" \".join, axis=1))\n",
        "X = df[\"all_text\"].astype(str).values\n",
        "y = df[\"topic\"].astype(str).values\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5gHfzpf9_EA"
      },
      "source": [
        "Q3 checking data balance, the distribution of types is close to uniform in some topics but unbalance on lifestyle and emotion topics. Accuracy may be dominated by dark, sadness and personal, taking both accuracy and f1_macro into account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFMNK2mHxUJ8",
        "outputId": "6de8f4c1-befe-4789-bdf8-9b471d53134d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "topic\n",
            "dark         0.329054\n",
            "sadness      0.250676\n",
            "personal     0.230405\n",
            "lifestyle    0.136486\n",
            "emotion      0.053378\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "vc = df[\"topic\"].value_counts(normalize=True)\n",
        "print(vc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ja8BD0GF-lIS"
      },
      "outputs": [],
      "source": [
        "scoring = [\"accuracy\",\"f1_macro\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuXTcbZV-2NZ"
      },
      "source": [
        "Q3 perform grid search and cross validate on both BNB and MNB, and on all param combination listed in previous cells.\n",
        "\n",
        "For each round, record model (bnb and mnb), and param combinations. Also record mean accuracy, accuracy standard deviation, mean f1_macro, f1_macro standard deviation as result indicators. Using mainly mean accuracy & f1_macro as main indicator to sort result (aka model and param combination) quality.\n",
        "\n",
        "Print top ten results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XocOUAmtRy7W",
        "outputId": "519ca9a2-1178-4a07-e61b-9b180e3b0d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "  clean_pattern  lower   ngram stop_option tok_mode          model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0       default   True  (1, 1)        nltk     stem  MultinomialNB  0.811486  0.014865  0.751374  0.029059\n",
            "1       default  False  (1, 1)        nltk     stem  MultinomialNB  0.811486  0.014865  0.751374  0.029059\n",
            "2   less_symbol   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "3   less_symbol  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "4   more_symbol   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "5   more_symbol  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "6       default   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748020  0.027031\n",
            "7       default  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748020  0.027031\n",
            "8   less_symbol   True  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n",
            "9   less_symbol  False  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n"
          ]
        }
      ],
      "source": [
        "records = []\n",
        "rounds = 0\n",
        "for params in ParameterGrid(param_grid): # under all possible param combination\n",
        "  for clf in (BernoulliNB(), MultinomialNB()): # checking both BNB & MNB in one search\n",
        "    pipe = build_pipeline(clf, **params)\n",
        "    cv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "    rounds += 1\n",
        "    print(rounds)\n",
        "    records.append({\n",
        "      **params,\n",
        "      \"model\": clf.__class__.__name__,\n",
        "      \"acc_mean\": np.mean(cv_res[\"test_accuracy\"]),\n",
        "      \"acc_std\": np.std(cv_res[\"test_accuracy\"]),\n",
        "      \"f1_mean\": np.mean(cv_res[\"test_f1_macro\"]),\n",
        "      \"f1_std\": np.std(cv_res[\"test_f1_macro\"])\n",
        "    })\n",
        "\n",
        "results = (pd.DataFrame(records).sort_values([\"f1_mean\",\"acc_mean\"], ascending=False).reset_index(drop=True))\n",
        "print(results.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSO_DMb2B4s8"
      },
      "source": [
        "Printing more results to evaluate both models. It's clear that MMB occupies top part of result sheet with noticable accuracy and f1_macro. This possibly because MNB takes word frequency info into account, thus having more expressive power. BNB only checks weather a word appears.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTuJNdnKXW0w",
        "outputId": "5c44d243-e35d-47f2-b1f3-470eab1394a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   clean_pattern  lower   ngram stop_option tok_mode          model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0        default   True  (1, 1)        nltk     stem  MultinomialNB  0.811486  0.014865  0.751374  0.029059\n",
            "1        default  False  (1, 1)        nltk     stem  MultinomialNB  0.811486  0.014865  0.751374  0.029059\n",
            "2    less_symbol   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "3    less_symbol  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "4    more_symbol   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "5    more_symbol  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748214  0.026788\n",
            "6        default   True  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748020  0.027031\n",
            "7        default  False  (1, 1)        None    lemma  MultinomialNB  0.812162  0.008705  0.748020  0.027031\n",
            "8    less_symbol   True  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n",
            "9    less_symbol  False  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n",
            "10   more_symbol   True  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n",
            "11   more_symbol  False  (1, 1)        nltk     stem  MultinomialNB  0.810135  0.014397  0.747341  0.029407\n",
            "12       default   True  (1, 1)        None     stem  MultinomialNB  0.808784  0.011427  0.746709  0.028044\n",
            "13       default  False  (1, 1)        None     stem  MultinomialNB  0.808784  0.011427  0.746709  0.028044\n",
            "14       default   True  (1, 1)        nltk    lemma  MultinomialNB  0.813514  0.010336  0.746636  0.027283\n",
            "15       default  False  (1, 1)        nltk    lemma  MultinomialNB  0.813514  0.010336  0.746636  0.027283\n",
            "16   less_symbol   True  (1, 1)        None     stem  MultinomialNB  0.807432  0.012997  0.745336  0.028936\n",
            "17   less_symbol  False  (1, 1)        None     stem  MultinomialNB  0.807432  0.012997  0.745336  0.028936\n",
            "18   more_symbol   True  (1, 1)        None     stem  MultinomialNB  0.807432  0.012997  0.745336  0.028936\n",
            "19   more_symbol  False  (1, 1)        None     stem  MultinomialNB  0.807432  0.012997  0.745336  0.028936\n",
            "20   less_symbol   True  (1, 1)        nltk    lemma  MultinomialNB  0.812162  0.010158  0.744892  0.026645\n",
            "21   less_symbol  False  (1, 1)        nltk    lemma  MultinomialNB  0.812162  0.010158  0.744892  0.026645\n",
            "22   more_symbol   True  (1, 1)        nltk    lemma  MultinomialNB  0.812162  0.010158  0.744892  0.026645\n",
            "23   more_symbol  False  (1, 1)        nltk    lemma  MultinomialNB  0.812162  0.010158  0.744892  0.026645\n",
            "24       default   True  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740618  0.030237\n",
            "25       default  False  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740618  0.030237\n",
            "26   less_symbol   True  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740616  0.030237\n",
            "27   less_symbol  False  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740616  0.030237\n",
            "28   more_symbol   True  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740616  0.030237\n",
            "29   more_symbol  False  (1, 1)        nltk     none  MultinomialNB  0.808784  0.010380  0.740616  0.030237\n"
          ]
        }
      ],
      "source": [
        "print(results.head(30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ouP15tOgDmI1",
        "outputId": "3027a91f-c401-4bea-f48c-2ca4844ba25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    clean_pattern  lower   ngram stop_option tok_mode        model  acc_mean   acc_std   f1_mean    f1_std\n",
            "186   more_symbol  False  (1, 2)        nltk     stem  BernoulliNB  0.335811  0.005489  0.110224  0.007932\n",
            "187   more_symbol  False  (1, 2)        nltk    lemma  BernoulliNB  0.335811  0.005489  0.110224  0.007932\n",
            "188   less_symbol   True  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "189   less_symbol  False  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "190       default   True  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "191       default  False  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "192   more_symbol   True  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "193   more_symbol  False  (1, 2)     sklearn     none  BernoulliNB  0.335811  0.006957  0.110212  0.009511\n",
            "194       default   True  (1, 2)        nltk    lemma  BernoulliNB  0.335811  0.005489  0.110187  0.007955\n",
            "195       default  False  (1, 2)        nltk    lemma  BernoulliNB  0.335811  0.005489  0.110187  0.007955\n",
            "196       default   True  (1, 2)        nltk     stem  BernoulliNB  0.335135  0.004482  0.109161  0.006529\n",
            "197       default  False  (1, 2)        nltk     stem  BernoulliNB  0.335135  0.004482  0.109161  0.006529\n",
            "198   less_symbol   True  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "199   less_symbol  False  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "200       default   True  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "201       default  False  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "202   more_symbol   True  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "203   more_symbol  False  (1, 2)        nltk     none  BernoulliNB  0.335135  0.005405  0.109137  0.007607\n",
            "204   less_symbol   True  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "205   less_symbol   True  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "206   less_symbol  False  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "207   less_symbol  False  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "208       default   True  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "209       default   True  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "210       default  False  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "211       default  False  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "212   more_symbol   True  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "213   more_symbol   True  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "214   more_symbol  False  (1, 2)        None     none  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n",
            "215   more_symbol  False  (1, 2)        None    lemma  BernoulliNB  0.334459  0.005653  0.108061  0.007839\n"
          ]
        }
      ],
      "source": [
        "print(results.tail(30))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZvu4_ddFsyR"
      },
      "source": [
        "Colour belt of MNB and BNB distribution shows clearly that under previous evaluation (accuracy and f1_macro), MNB appears in top half of the belt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "d2PbuhR4Esh3",
        "outputId": "aeb404f0-0a3a-40c3-aee3-0c8ed45195f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABp4AAABwCAYAAAAHfgPKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABOhJREFUeJzt3TGO00AYhuHfUbY0EW20ER0HoOYEXJaOE3ADOiqkSD5AZjuQhwItpbGUb+WEfZ56iq8dvbJn6L33AgAAAAAAgCvtth4AAAAAAADA/0F4AgAAAAAAIEJ4AgAAAAAAIEJ4AgAAAAAAIEJ4AgAAAAAAIEJ4AgAAAAAAIEJ4AgAAAAAAIEJ4AgAAAAAAIGK/5tA8zzVNU43jWMMwvPQmAAAAAAAAbkTvvVprdTwea7db/qZpVXiapqlOp1NkHAAAAAAAAPfnfD7X4+Pj4plV4Wkcx6qq+lifal8P1y8DAAC4M5+/f9t6AgAAwCYuT3O9+/Djby9asio8Pf9eb18PtR+EJwAA4PV5M3oiFwAAeN3WPMfk5gQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAECE8AQAAAAAAEDEfs2h3ntVVf2qn1X9RfcAAADcpEubt54AAACwicvTn/vQcy9asio8tdaqquprfbliFgAAwP16+37rBQAAANtqrdXhcFg8M/QVeWqe55qmqcZxrGEYYgMBAAAAAAC4bb33aq3V8Xis3W75FadV4QkAAAAAAAD+ZTlLAQAAAAAAwErCEwAAAAAAABHCEwAAAAAAABHCEwAAAAAAABHCEwAAAAAAABHCEwAAAAAAABHCEwAAAAAAABG/AbzfSK/Ev2uKAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 2160x120 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "models = results[\"model\"]\n",
        "counts = models.value_counts()\n",
        "\n",
        "\n",
        "labels, unique_models = pd.factorize(models)\n",
        "data = labels.reshape(1, -1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(len(models)/10, 1.2))\n",
        "im = ax.imshow(data, aspect='auto')\n",
        "ax.set_yticks([])\n",
        "ax.set_xticks([])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wizhQVV2GGpz"
      },
      "source": [
        "Thus we finished Q1-3 with:\n",
        "\n",
        "Removing less special characters(symols) by regex; apply 5 fold cross validate\n",
        "\n",
        "Applying MNB model, make all step in prepross and other params (stop option,ngram,tokenize mode) selectable in grid search, and performing that grid search to find best setps & params that performs better.\n",
        "\n",
        "Best param fixed as: default clean pattern(keep numbers,',/), ngram(1,1), stop words nltk(english), tokenize mode lemma(lemmatizer), model MultinomialNB\n",
        "\n",
        "Compared both BNB and MNB when doing grid search (doubled amount of calculation, shouldn't do that), chosed mean accuracy and f1_macro due to distribution of topics. (accuracy for over all correct rate and f1_macro for accuracy of lifestyle and emotion not suppressed by other major topics). Finally confirmed that MNB outperformed BNB over all cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHcCdxgcI4K1"
      },
      "source": [
        "## Q4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56Z07bYLNVkb"
      },
      "source": [
        "Set up feature word num list, none for all words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "UNaFSc2sI7QN"
      },
      "outputs": [],
      "source": [
        "N_list = [500, 1000, 2000, 5000, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzrWFAYTRycN"
      },
      "source": [
        "Build same pipeline as previous, but fix param choice as best params.\n",
        "Add N to count vectorizer as demanded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "i2dt6uP3NmGK"
      },
      "outputs": [],
      "source": [
        "# def build_pipeline(clf, clean_pattern=\"default\", lower=True, stop_option=None, ngram=(1,1), tok_mode=\"none\"):\n",
        "#   vect = CountVectorizer(\n",
        "#     analyzer=make_analyzer(lower, clean_pattern, tok_mode, stop_option, ngram),\n",
        "#     lowercase=False, # all set to none, process by analyzer\n",
        "#     preprocessor=None,\n",
        "#     tokenizer=None,\n",
        "#     token_pattern=None\n",
        "#   )\n",
        "#   steps = [(\"vect\", vect)]\n",
        "#   if isinstance(clf, BernoulliNB): # add binarizer if BNB\n",
        "#     steps.append((\"bin\", Binarizer(copy=False)))\n",
        "#   steps.append((\"clf\", clf)) # mnb & bnb\n",
        "#   return Pipeline(steps)\n",
        "\n",
        "def build_pipeline2(clf, N):\n",
        "  vect = CountVectorizer(\n",
        "    analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)), # best params from result above (default clean pattern(keep numbers,',/), ngram(1,1), stop words nltk, tokenize mode lemma, model MultinomialNB)\n",
        "    lowercase=False,\n",
        "    preprocessor=None,\n",
        "    tokenizer=None,\n",
        "    token_pattern=None,\n",
        "    max_features = N\n",
        "  )\n",
        "  steps = [(\"vect\", vect)]\n",
        "  if isinstance(clf, BernoulliNB): # add binarizer if BNB\n",
        "    steps.append((\"bin\", Binarizer(copy=False)))\n",
        "  steps.append((\"clf\", clf)) # mnb & bnb\n",
        "  return Pipeline(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDc3o-X3Ogmp"
      },
      "source": [
        "First test on both BNB & MNB, result shows that MNB still outperforms BNB, stop using BNB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MWaXuqMOi1W",
        "outputId": "764ee6c1-8284-4aa8-f389-2564c5cec05c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "   N_words          model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0    500.0  MultinomialNB  0.878378  0.008810  0.859398  0.016812\n",
            "1   1000.0  MultinomialNB  0.851351  0.019111  0.830415  0.027860\n",
            "2   2000.0  MultinomialNB  0.837838  0.010895  0.812834  0.012560\n",
            "3   5000.0  MultinomialNB  0.826351  0.011819  0.788593  0.024462\n",
            "4      NaN  MultinomialNB  0.813514  0.010336  0.746636  0.027283\n",
            "5    500.0    BernoulliNB  0.652703  0.019975  0.545675  0.025017\n",
            "6   1000.0    BernoulliNB  0.634459  0.022348  0.517704  0.022559\n",
            "7   2000.0    BernoulliNB  0.617568  0.018055  0.481111  0.013658\n",
            "8   5000.0    BernoulliNB  0.566216  0.032235  0.391787  0.021503\n",
            "9      NaN    BernoulliNB  0.537162  0.015555  0.336253  0.013826\n"
          ]
        }
      ],
      "source": [
        "records = []\n",
        "rounds = 0\n",
        "for N in N_list: # under all possible N\n",
        "  for clf in (BernoulliNB(), MultinomialNB()): # checking both BNB & MNB in one search\n",
        "    pipe = build_pipeline2(clf, N)\n",
        "    cv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "    rounds += 1\n",
        "    print(rounds)\n",
        "    records.append({\n",
        "      \"N_words\": N,\n",
        "      \"model\": clf.__class__.__name__,\n",
        "      \"acc_mean\": np.mean(cv_res[\"test_accuracy\"]),\n",
        "      \"acc_std\": np.std(cv_res[\"test_accuracy\"]),\n",
        "      \"f1_mean\": np.mean(cv_res[\"test_f1_macro\"]),\n",
        "      \"f1_std\": np.std(cv_res[\"test_f1_macro\"])\n",
        "    })\n",
        "\n",
        "results = (pd.DataFrame(records).sort_values([\"f1_mean\",\"acc_mean\"], ascending=False).reset_index(drop=True))\n",
        "print(results.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mISkhga6Sr8M"
      },
      "source": [
        "Checking wether N<500 has better result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV_xSxG1QI0f",
        "outputId": "bbeddb1a-fb7c-41aa-b98f-735fdf71f02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "   N_words          model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0      400  MultinomialNB  0.869595  0.009215  0.852948  0.017556\n",
            "1      200  MultinomialNB  0.830405  0.007822  0.813398  0.007534\n",
            "2      100  MultinomialNB  0.753378  0.024734  0.732895  0.023690\n",
            "3       50  MultinomialNB  0.676351  0.035587  0.646436  0.032071\n"
          ]
        }
      ],
      "source": [
        "N_list = [50, 100, 200, 400]\n",
        "records = []\n",
        "rounds = 0\n",
        "for N in N_list: # under all possible param combination\n",
        "  clf = MultinomialNB() # checking both BNB & MNB in one search\n",
        "  pipe = build_pipeline2(clf, N)\n",
        "  cv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "  rounds += 1\n",
        "  print(rounds)\n",
        "  records.append({\n",
        "    \"N_words\": N,\n",
        "    \"model\": clf.__class__.__name__,\n",
        "    \"acc_mean\": np.mean(cv_res[\"test_accuracy\"]),\n",
        "    \"acc_std\": np.std(cv_res[\"test_accuracy\"]),\n",
        "    \"f1_mean\": np.mean(cv_res[\"test_f1_macro\"]),\n",
        "    \"f1_std\": np.std(cv_res[\"test_f1_macro\"])\n",
        "  })\n",
        "\n",
        "results = (pd.DataFrame(records).sort_values([\"f1_mean\",\"acc_mean\"], ascending=False).reset_index(drop=True))\n",
        "print(results.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fiLOpRMSzLa"
      },
      "source": [
        "Confirm that N = around 500 is the best feature num value as it creats best over all accuracy and f1_macro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnOxBb7pQucZ",
        "outputId": "cdb3f6e5-eab9-46b1-a9b9-cafd20ce1b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "   N_words          model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0      500  MultinomialNB  0.878378  0.008810  0.859398  0.016812\n",
            "1      550  MultinomialNB  0.875000  0.009791  0.853793  0.014487\n",
            "2      400  MultinomialNB  0.869595  0.009215  0.852948  0.017556\n",
            "3      450  MultinomialNB  0.872297  0.009411  0.852844  0.016944\n",
            "4      600  MultinomialNB  0.873649  0.008964  0.851404  0.011281\n",
            "5      350  MultinomialNB  0.864189  0.010978  0.849503  0.015358\n",
            "6      300  MultinomialNB  0.864865  0.013681  0.846685  0.019362\n"
          ]
        }
      ],
      "source": [
        "N_list = [300, 350, 400, 450, 500, 550, 600]\n",
        "records = []\n",
        "rounds = 0\n",
        "for N in N_list: # under all possible param combination\n",
        "  clf = MultinomialNB() # checking both BNB & MNB in one search\n",
        "  pipe = build_pipeline2(clf, N)\n",
        "  cv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "  rounds += 1\n",
        "  print(rounds)\n",
        "  records.append({\n",
        "    \"N_words\": N,\n",
        "    \"model\": clf.__class__.__name__,\n",
        "    \"acc_mean\": np.mean(cv_res[\"test_accuracy\"]),\n",
        "    \"acc_std\": np.std(cv_res[\"test_accuracy\"]),\n",
        "    \"f1_mean\": np.mean(cv_res[\"test_f1_macro\"]),\n",
        "    \"f1_std\": np.std(cv_res[\"test_f1_macro\"])\n",
        "  })\n",
        "\n",
        "results = (pd.DataFrame(records).sort_values([\"f1_mean\",\"acc_mean\"], ascending=False).reset_index(drop=True))\n",
        "print(results.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pwvnstnTyNL"
      },
      "source": [
        "## Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYPfFkIo-Mu3"
      },
      "source": [
        "Choose logistic regression as the third model(for I used this in previous subjects of 9417 and it worked well)\n",
        "\n",
        "Logistic regression is a linear classifier that predicts the probability of a category by perform a weighted linear combination of input features and apply sigmoid function. It is a discriminative model that directly models the posterior probability. It often performs stably in high-dimensional sparse text classification scenarios, and can control overfitting through regularization.\n",
        "\n",
        "In this case with high dimentional and sparse lyrics, logistic regression can retain the interpretability of the linear model and also adjust the model complexity through regularization.Thus I chose this model. I assume this model will atleast outperform both MNB and BNB on f1_macro since it can minimize classification loss and use full word frequency information, and accuracy at least the same or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "mLhf6om4Tz3e"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUZPgVi-ICGS"
      },
      "source": [
        "Still use the same pipeline function, add fixed N_word num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "DW9Ei6t9T-Fa"
      },
      "outputs": [],
      "source": [
        "def build_pipeline3(clf):\n",
        "  vect = CountVectorizer(\n",
        "    analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)), # best params from result above (default clean pattern(keep numbers,',/), ngram(1,1), stop words nltk, tokenize mode lemma, model MultinomialNB)\n",
        "    lowercase=False,\n",
        "    preprocessor=None,\n",
        "    tokenizer=None,\n",
        "    token_pattern=None,\n",
        "    max_features = 500\n",
        "  )\n",
        "  steps = [(\"vect\", vect)]\n",
        "  if isinstance(clf, BernoulliNB): # add binarizer if BNB\n",
        "    steps.append((\"bin\", Binarizer(copy=False)))\n",
        "  steps.append((\"clf\", clf)) # mnb & bnb & lr\n",
        "  return Pipeline(steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ry2aHacJBIT"
      },
      "source": [
        "Still use the same 5 fold cross validate and evaluation based on accuracy and f1_macro. Apply same validate on 3 model under the same best params obtained above.\n",
        "\n",
        "LR is applied at basically default settings, since lbfgs works well on small amount of data.\n",
        "\n",
        "From the results we can see the mean accuracy and f1_macro are slightly higher than that of LR, which significantly higher than that of BNB.\n",
        "\n",
        "MNB and LR shows relatively close results, but disconfirmed my assumption of LR being supiror to MNB. However its difference is smaller than 1%. I assume this is because parameter estimation of Naive Bayes is more stable in this data, and MNB as a generative model has better resistant to noise than LR. Also, the test is run under the best params of MNB, since I haven't do grid search based on LR, it might not be the best params for LR. So I cannot confirm MNB is better than LR in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8hmfDIiWba8",
        "outputId": "c2deca2c-7bda-4f6a-ac5e-048cd59ff597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "                model  acc_mean   acc_std   f1_mean    f1_std\n",
            "0       MultinomialNB  0.878378  0.008810  0.859398  0.016812\n",
            "1  LogisticRegression  0.867568  0.010768  0.848311  0.016608\n",
            "2         BernoulliNB  0.652703  0.019975  0.545675  0.025017\n"
          ]
        }
      ],
      "source": [
        "records = []\n",
        "rounds = 0\n",
        "#for N in N_list: # under all possible N\n",
        "for clf in (BernoulliNB(), MultinomialNB(), LogisticRegression(penalty=\"l2\", C=1.0, solver=\"lbfgs\", max_iter=1000)): # apply LR with default settings\n",
        "  pipe = build_pipeline3(clf)\n",
        "  cv_res = cross_validate(pipe, X, y, cv=cv, scoring=scoring, return_train_score=False)\n",
        "  rounds += 1\n",
        "  print(rounds)\n",
        "  records.append({\n",
        "    \"model\": clf.__class__.__name__,\n",
        "    \"acc_mean\": np.mean(cv_res[\"test_accuracy\"]),\n",
        "    \"acc_std\": np.std(cv_res[\"test_accuracy\"]),\n",
        "    \"f1_mean\": np.mean(cv_res[\"test_f1_macro\"]),\n",
        "    \"f1_std\": np.std(cv_res[\"test_f1_macro\"])\n",
        "  })\n",
        "\n",
        "results = (pd.DataFrame(records).sort_values([\"f1_mean\",\"acc_mean\"], ascending=False).reset_index(drop=True))\n",
        "print(results.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUXlcqD-aTDg"
      },
      "source": [
        "  Thus the best model & params is fixed as:\n",
        "\n",
        "  MNB\n",
        "\n",
        "  make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1))\n",
        "\n",
        "  max_features = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFXygyukavVn"
      },
      "source": [
        "# Part2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWqDR5D91nzr"
      },
      "source": [
        "Q1\n",
        "\n",
        "Train-test split as demanded. 0-750 751-1000. Keep the text cols as previous.\n",
        "Triggred a chain assignment warning. Dose not matter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B0l14d3Taf1l",
        "outputId": "a52b3375-d856-4808-e285-b0641f0cca02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-171-1204292954.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[\"all_text\"] = (train[text_cols].fillna(\"\").agg(\" \".join, axis=1))\n",
            "/tmp/ipython-input-171-1204292954.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[\"all_text\"] = (test[text_cols].fillna(\"\").agg(\" \".join, axis=1))\n"
          ]
        }
      ],
      "source": [
        "df2 = pd.read_csv(master_path + 'dataset.tsv', sep='\\t')\n",
        "\n",
        "train = df2.iloc[:750]\n",
        "test = df2.iloc[750:1000]\n",
        "\n",
        "text_cols = [\"artist_name\", \"track_name\", \"genre\", \"lyrics\"]\n",
        "train[\"all_text\"] = (train[text_cols].fillna(\"\").agg(\" \".join, axis=1))\n",
        "test[\"all_text\"] = (test[text_cols].fillna(\"\").agg(\" \".join, axis=1))\n",
        "X_train = train[\"all_text\"].astype(str).values\n",
        "y_train = train[\"topic\"].astype(str).values\n",
        "X_test = test[\"all_text\"].astype(str).values\n",
        "#y_test = test[\"topic\"].astype(str).values # im a idiot (\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohmYxjst-d8f"
      },
      "source": [
        "Reuse the pipeline from above, train classifier on train set, generate topic prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "G8WTrJsP7RCn"
      },
      "outputs": [],
      "source": [
        "# def build_pipeline3(clf):\n",
        "#   vect = CountVectorizer(\n",
        "#     analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)), # best params from result above (default clean pattern(keep numbers,',/), ngram(1,1), stop words nltk, tokenize mode lemma, model MultinomialNB)\n",
        "#     lowercase=False,\n",
        "#     preprocessor=None,\n",
        "#     tokenizer=None,\n",
        "#     token_pattern=None,\n",
        "#     max_features = 500\n",
        "#   )\n",
        "#   steps = [(\"vect\", vect)]\n",
        "#   if isinstance(clf, BernoulliNB): # add binarizer if BNB\n",
        "#     steps.append((\"bin\", Binarizer(copy=False)))\n",
        "#   steps.append((\"clf\", clf)) # mnb & bnb & lr\n",
        "#   return Pipeline(steps)\n",
        "\n",
        "pipe = build_pipeline3(MultinomialNB()) # params already in build pipeline3, only name clf\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred_train = pipe.predict(X_train)\n",
        "y_pred_test = pipe.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqlXqGeY6i1n"
      },
      "source": [
        "Generate user's topic-keywords as matches, delete first line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdAsJxXk3OV-",
        "outputId": "6460929c-a5e3-4a71-bc38-01e1ad05481d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dark': ['fire', 'enemy', 'pain', 'storm', 'fight'], 'sadness': ['cry', 'alone', 'heartbroken', 'tears', 'regret'], 'personal': ['dream', 'truth', 'life', 'growth', 'identity'], 'lifestyle': ['party', 'city', 'night', 'light', 'rhythm'], 'emotion': ['love', 'memory', 'hug', 'kiss', 'feel']} {'sadness': ['lost', 'sorrow', 'goodbye', 'tears', 'silence'], 'emotion': ['romance', 'touch', 'feeling', 'kiss', 'memory']}\n"
          ]
        }
      ],
      "source": [
        "user1_kw = {}\n",
        "user2_kw = {}\n",
        "user3_kw = {}\n",
        "for line in open(master_path + 'user1.tsv', encoding=\"utf-8\"): # generate match\n",
        "  topic, kws = line.strip().split(\"\\t\")\n",
        "  user1_kw[topic] = [w.strip().lower() for w in kws.split(\",\")]\n",
        "\n",
        "for line in open(master_path + 'user2.tsv', encoding=\"utf-8\"):\n",
        "  topic, kws = line.strip().split(\"\\t\")\n",
        "  user2_kw[topic] = [w.strip().lower() for w in kws.split(\",\")]\n",
        "\n",
        "del user1_kw['topic'] # delete first line\n",
        "del user2_kw['topic']\n",
        "print(user1_kw,user2_kw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdP59g-OBzFj"
      },
      "source": [
        "For each song in train set, if prediction topic is current topic and there exist any user key word in text, consider this song as user liked. mark index of those songs in list as matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HBy6s-x6yv4",
        "outputId": "de3417d7-aee3-473a-a985-40f293d9eae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dark': [0, 8, 37, 52, 64, 68, 71, 72, 79, 81, 83, 88, 95, 97, 110, 113, 119, 129, 132, 139, 140, 145, 153, 155, 162, 163, 178, 182, 203, 208, 209, 214, 218, 228, 252, 256, 264, 265, 266, 278, 293, 298, 301, 307, 317, 333, 362, 363, 365, 368, 400, 408, 416, 425, 454, 471, 472, 478, 485, 488, 515, 540, 556, 560, 571, 574, 576, 592, 601, 603, 613, 614, 643, 654, 660, 662, 669, 681, 686, 688, 690, 722, 723, 749], 'emotion': [5, 18, 33, 34, 56, 85, 229, 248, 284, 318, 327, 330, 364, 374, 403, 412, 423, 448, 484, 513, 541, 593, 620, 633, 724, 728, 734, 741], 'lifestyle': [16, 47, 55, 65, 69, 80, 92, 105, 117, 154, 158, 166, 173, 204, 205, 213, 215, 231, 250, 268, 295, 299, 328, 335, 354, 384, 429, 455, 457, 467, 494, 496, 502, 506, 510, 546, 577, 591, 598, 600, 615, 616, 630, 652, 712, 731, 740, 746], 'personal': [10, 12, 14, 25, 27, 41, 50, 66, 77, 93, 96, 99, 101, 102, 111, 126, 130, 138, 141, 168, 180, 185, 188, 194, 195, 198, 200, 210, 220, 221, 223, 225, 235, 238, 244, 249, 251, 258, 260, 267, 272, 283, 286, 294, 302, 310, 313, 319, 320, 324, 346, 367, 372, 376, 377, 378, 381, 389, 391, 420, 426, 433, 434, 435, 444, 446, 450, 452, 461, 462, 468, 490, 498, 499, 504, 524, 532, 534, 535, 542, 551, 553, 555, 565, 568, 572, 575, 582, 583, 587, 595, 597, 602, 604, 607, 608, 628, 629, 631, 632, 636, 644, 647, 653, 657, 671, 675, 687, 689, 695, 696, 708, 711, 729, 732, 733, 735, 739, 742, 745], 'sadness': [19, 49, 150, 247, 383, 413, 523, 531, 561, 566, 743]}\n",
            "{'dark': [], 'emotion': [5, 34, 56, 248, 327, 364, 412, 423, 448, 484, 541, 633, 728, 741], 'lifestyle': [], 'personal': [], 'sadness': [21, 29, 137, 143, 181, 288, 334, 336, 355, 370, 383, 411, 440, 482, 489, 627, 700, 721, 727, 743]}\n"
          ]
        }
      ],
      "source": [
        "topics = pipe.classes_.tolist()\n",
        "\n",
        "def user_liked(user_kw, df, y_pred):\n",
        "  liked = {t: [] for t in topics}\n",
        "  for idx, row in df.iterrows():\n",
        "    topic = y_pred[idx]\n",
        "    text = (row['artist_name'] + ' ' + row['track_name'] + ' ' + row['genre'] + ' ' + row['lyrics']).lower()\n",
        "    if any(kw in text for kw in user_kw.get(topic, [])): # found kw match, append song id into list\n",
        "      liked[topic].append(idx)\n",
        "  return liked\n",
        "\n",
        "liked1 = user_liked(user1_kw, train, y_pred_train)\n",
        "print(liked1)\n",
        "liked2 = user_liked(user2_kw, train, y_pred_train)\n",
        "print(liked2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUUYG-FiLpFz"
      },
      "source": [
        "Create a tfdif vectorizer using the exact same param and text preprocess as previous(same function call), and vectorize user's like song's text in each topic into tfidf vector(thus five vectors), store it into dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIEd44gHGKU2",
        "outputId": "519cc3fb-47bb-4328-beb2-0df737737942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dark': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 454 stored elements and shape (1, 500)>, 'emotion': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 295 stored elements and shape (1, 500)>, 'lifestyle': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 358 stored elements and shape (1, 500)>, 'personal': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 466 stored elements and shape (1, 500)>, 'sadness': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 171 stored elements and shape (1, 500)>}\n",
            "{'dark': None, 'emotion': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 207 stored elements and shape (1, 500)>, 'lifestyle': None, 'personal': None, 'sadness': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 242 stored elements and shape (1, 500)>}\n"
          ]
        }
      ],
      "source": [
        "#   vect = CountVectorizer(\n",
        "#     analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)), # best params from result above (default clean pattern(keep numbers,',/), ngram(1,1), stop words nltk, tokenize mode lemma, model MultinomialNB)\n",
        "#     lowercase=False,\n",
        "#     preprocessor=None,\n",
        "#     tokenizer=None,\n",
        "#     token_pattern=None,\n",
        "#     max_features = 500\n",
        "#   )\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# tfidf = TfidfVectorizer( #using same params as above\n",
        "#     max_features=500,\n",
        "#     analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)),\n",
        "#     lowercase=1,\n",
        "#     token_pattern=None,\n",
        "#     stop_words=None\n",
        "#     )\n",
        "\n",
        "tfidf_global = TfidfVectorizer( #using same params as above\n",
        "    max_features=500,\n",
        "    analyzer=make_analyzer(0, \"default\", \"lemma\", \"nltk\", (1,1)),\n",
        "    lowercase=False, # also disable default process as done in analyzer\n",
        "    token_pattern=None,\n",
        "    stop_words=None\n",
        "    )\n",
        "\n",
        "tfidf_global.fit(X_train)\n",
        "tfidf = tfidf_global.transform(X_train) # fit & vectorize globally, otherwise can't be compared by cos sim\n",
        "\n",
        "user1_topic_vecs = {} # result dict. suppose to map topic to vector for each topic liked\n",
        "for topic in topics:\n",
        "  liked_idx = liked1[topic]\n",
        "  if not liked_idx:  # user liked nothing under topic\n",
        "    user1_topic_vecs[topic] = None\n",
        "  else:\n",
        "    mat = tfidf[liked_idx] # shape = (n_liked, n_features)\n",
        "    user1_topic_vecs[topic] = sp.csr_matrix(mat.sum(axis=0))\n",
        "\n",
        "print(user1_topic_vecs)\n",
        "\n",
        "user2_topic_vecs = {}\n",
        "for topic in topics:\n",
        "  liked_idx = liked2[topic]\n",
        "  if not liked_idx:\n",
        "    user2_topic_vecs[topic] = None\n",
        "  else:\n",
        "    mat = tfidf[liked_idx]\n",
        "    user2_topic_vecs[topic] = sp.csr_matrix(mat.sum(axis=0))\n",
        "\n",
        "print(user2_topic_vecs)\n",
        "# vectors for different users. left blank if user not have such topic in matches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3LFoYf1noDA"
      },
      "source": [
        "Print top 20 words for each topic liked for each user.\n",
        "\n",
        "These words seems reasonable, for example:\n",
        "\n",
        "Topic:dark\n",
        "fight\n",
        "stand\n",
        "black\n",
        "know\n",
        "like\n",
        "come\n",
        "blood\n",
        "kill\n",
        "\n",
        "Topic:sadness\n",
        "cry\n",
        "tear\n",
        "steal\n",
        "mean\n",
        "know\n",
        "smile\n",
        "club\n",
        "baby\n",
        "blame\n",
        "\n",
        "It suits common sense, I assume this means classification works well.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crS56pr_kDB3",
        "outputId": "73cede56-1dfa-425b-86d2-ec944586a2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Topic:dark\n",
            "fight\n",
            "stand\n",
            "black\n",
            "know\n",
            "like\n",
            "come\n",
            "blood\n",
            "kill\n",
            "hand\n",
            "gonna\n",
            "build\n",
            "grind\n",
            "head\n",
            "soul\n",
            "tell\n",
            "wall\n",
            "rise\n",
            "death\n",
            "time\n",
            "fall\n",
            "\n",
            " Topic:emotion\n",
            "good\n",
            "feel\n",
            "kiss\n",
            "hold\n",
            "touch\n",
            "morning\n",
            "love\n",
            "lip\n",
            "go\n",
            "know\n",
            "miss\n",
            "want\n",
            "baby\n",
            "luck\n",
            "feelin\n",
            "heart\n",
            "vibe\n",
            "sunrise\n",
            "light\n",
            "video\n",
            "\n",
            " Topic:lifestyle\n",
            "night\n",
            "song\n",
            "tonight\n",
            "sing\n",
            "time\n",
            "home\n",
            "come\n",
            "right\n",
            "wait\n",
            "long\n",
            "play\n",
            "want\n",
            "baby\n",
            "mind\n",
            "like\n",
            "radio\n",
            "stay\n",
            "late\n",
            "girl\n",
            "hate\n",
            "\n",
            " Topic:personal\n",
            "life\n",
            "live\n",
            "world\n",
            "dream\n",
            "change\n",
            "know\n",
            "thing\n",
            "yeah\n",
            "time\n",
            "like\n",
            "learn\n",
            "come\n",
            "wanna\n",
            "think\n",
            "grow\n",
            "go\n",
            "want\n",
            "believe\n",
            "thank\n",
            "forever\n",
            "\n",
            " Topic:sadness\n",
            "cry\n",
            "tear\n",
            "steal\n",
            "mean\n",
            "know\n",
            "smile\n",
            "club\n",
            "baby\n",
            "blame\n",
            "stay\n",
            "face\n",
            "think\n",
            "fear\n",
            "soul\n",
            "write\n",
            "place\n",
            "want\n",
            "word\n",
            "come\n",
            "eye\n",
            "dark: not liked\n",
            "\n",
            " Topic:emotion\n",
            "kiss\n",
            "touch\n",
            "good\n",
            "lip\n",
            "hold\n",
            "morning\n",
            "luck\n",
            "love\n",
            "feelin\n",
            "sunrise\n",
            "video\n",
            "fade\n",
            "vision\n",
            "know\n",
            "loove\n",
            "time\n",
            "gimme\n",
            "go\n",
            "cause\n",
            "lovin\n",
            "lifestyle: not liked\n",
            "personal: not liked\n",
            "\n",
            " Topic:sadness\n",
            "break\n",
            "away\n",
            "heart\n",
            "tear\n",
            "fade\n",
            "inside\n",
            "fall\n",
            "scar\n",
            "hard\n",
            "open\n",
            "smile\n",
            "leave\n",
            "blame\n",
            "silence\n",
            "goodbye\n",
            "drift\n",
            "come\n",
            "know\n",
            "like\n",
            "go\n"
          ]
        }
      ],
      "source": [
        "feature_names = tfidf_global.get_feature_names_out()\n",
        "\n",
        "def print_top_terms(user_topic_vecs):\n",
        "  for topic, vec in user_topic_vecs.items():\n",
        "    if vec is None:\n",
        "      print(f\"{topic}: not liked\")\n",
        "      continue\n",
        "    arr = vec.toarray().ravel() # vector to 1 dim array, sort by weight, print\n",
        "    top_idx = arr.argsort()[::-1][:20] # get top 20\n",
        "    terms = [(feature_names[i], arr[i]) for i in top_idx]\n",
        "    print(f\"\\n Topic:{topic}\")\n",
        "    for term, weight in terms:\n",
        "      print(term)\n",
        "\n",
        "\n",
        "\n",
        "print_top_terms(user1_topic_vecs)\n",
        "print_top_terms(user2_topic_vecs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ5c-qjvqg7a"
      },
      "source": [
        "Seperate test on made up user3. Seems reasonable, but some of the words seems does not 100% match. Such as reggae in lifestyle, should be a style of music."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7gl9B5ApagJ",
        "outputId": "3a769df1-f1f9-436c-f8eb-7d9abed8c778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dark': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 434 stored elements and shape (1, 500)>, 'emotion': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 279 stored elements and shape (1, 500)>, 'lifestyle': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 259 stored elements and shape (1, 500)>, 'personal': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 126 stored elements and shape (1, 500)>, 'sadness': <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 370 stored elements and shape (1, 500)>}\n",
            "\n",
            " Topic:dark\n",
            "kill\n",
            "blood\n",
            "head\n",
            "like\n",
            "face\n",
            "stand\n",
            "come\n",
            "feat\n",
            "light\n",
            "grind\n",
            "death\n",
            "fight\n",
            "rise\n",
            "know\n",
            "break\n",
            "gonna\n",
            "lie\n",
            "breath\n",
            "wall\n",
            "feel\n",
            "\n",
            " Topic:emotion\n",
            "good\n",
            "feel\n",
            "touch\n",
            "morning\n",
            "love\n",
            "know\n",
            "hold\n",
            "miss\n",
            "lip\n",
            "want\n",
            "go\n",
            "kiss\n",
            "baby\n",
            "luck\n",
            "feelin\n",
            "heart\n",
            "vibe\n",
            "sunrise\n",
            "light\n",
            "video\n",
            "\n",
            " Topic:lifestyle\n",
            "long\n",
            "time\n",
            "home\n",
            "wait\n",
            "come\n",
            "late\n",
            "right\n",
            "night\n",
            "reggae\n",
            "summer\n",
            "call\n",
            "fine\n",
            "ready\n",
            "closer\n",
            "guitar\n",
            "ring\n",
            "struggle\n",
            "mind\n",
            "baby\n",
            "telephone\n",
            "\n",
            " Topic:personal\n",
            "youth\n",
            "believe\n",
            "house\n",
            "live\n",
            "life\n",
            "realize\n",
            "evil\n",
            "build\n",
            "thank\n",
            "hard\n",
            "matter\n",
            "people\n",
            "skin\n",
            "care\n",
            "dream\n",
            "right\n",
            "know\n",
            "home\n",
            "money\n",
            "go\n",
            "\n",
            " Topic:sadness\n",
            "heart\n",
            "break\n",
            "away\n",
            "cry\n",
            "think\n",
            "help\n",
            "fall\n",
            "leave\n",
            "know\n",
            "wish\n",
            "apart\n",
            "stay\n",
            "gonna\n",
            "mean\n",
            "pain\n",
            "tear\n",
            "like\n",
            "throw\n",
            "feel\n",
            "face\n"
          ]
        }
      ],
      "source": [
        "user3_kw = {'dark': ['kill', 'justice', 'bond', 'trap', 'war'], 'sadness': ['cry', 'help', 'future', 'less', 'why'], 'personal': ['youth', 'adult'], 'lifestyle': ['morning', 'dinner', 'egg', 'bed', 'sleep'], 'emotion': ['love', 'hate', 'jelous', 'feel']}\n",
        "liked3 = user_liked(user3_kw, train, y_pred_train)\n",
        "user3_topic_vecs = {}\n",
        "for topic in topics:\n",
        "  liked_idx = liked3[topic]\n",
        "  if not liked_idx:\n",
        "    user3_topic_vecs[topic] = None\n",
        "  else:\n",
        "    mat = tfidf[liked_idx]\n",
        "    user3_topic_vecs[topic] = sp.csr_matrix(mat.sum(axis=0))\n",
        "\n",
        "print(user3_topic_vecs)\n",
        "print_top_terms(user3_topic_vecs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoiE2JQI7uTq"
      },
      "source": [
        "Q2\n",
        "\n",
        "Build basic recommand system. Recommend num N is set to 34, which is two times the average num of song displayed on my favorite music app within one scroll(17). N = 17*2 because program has to preload content of next scroll to avoid lag. N is number of songs showed in total.\n",
        "\n",
        "Added different recommend algorithms for later comparism\n",
        "\n",
        "Skipped user unliked topic for easy coding. In reality there should be random recommandations from other topics for possible alternatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDXVZSj3Mqdi",
        "outputId": "7803d5b2-cb2e-4c4d-cf09-3c7299230175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(194, np.float64(0.6667605957313693)), (219, np.float64(0.6270901635353517)), (242, np.float64(0.6219887026660701)), (20, np.float64(0.5622032052648561)), (176, np.float64(0.4800266219681051)), (8, np.float64(0.4770821127057892)), (90, np.float64(0.4544171449668381)), (201, np.float64(0.43253368021718164)), (240, np.float64(0.42017427986936645)), (104, np.float64(0.41079234382826213)), (98, np.float64(0.40891713202903074)), (113, np.float64(0.4045338746776112)), (46, np.float64(0.3893278551717625)), (131, np.float64(0.3893073730862708)), (231, np.float64(0.3863195103243429)), (45, np.float64(0.3861416407165978)), (39, np.float64(0.37711682873933267)), (125, np.float64(0.3714826820359629)), (173, np.float64(0.37095325897272563)), (163, np.float64(0.36968967545317605)), (235, np.float64(0.3684215857363915)), (99, np.float64(0.36649397750217566)), (178, np.float64(0.3643340253656109)), (237, np.float64(0.36372529474607296)), (34, np.float64(0.3578461477731708)), (105, np.float64(0.3549750960065197)), (111, np.float64(0.3476740869065882)), (133, np.float64(0.3437157052179392)), (134, np.float64(0.343428945948381)), (65, np.float64(0.3415089820385351)), (42, np.float64(0.33660105042519156)), (6, np.float64(0.33116099146259637)), (151, np.float64(0.3299791780920945)), (89, np.float64(0.3171658348197189))]\n",
            "Recommand id: 194, Track name: once in a while, Track genre&topic: pop , emotion\n",
            "Recommand id: 219, Track name: got it good, Track genre&topic: country , emotion\n",
            "Recommand id: 242, Track name: i did something bad, Track genre&topic: pop , emotion\n",
            "Recommand id: 20, Track name: horsefly, Track genre&topic: reggae , emotion\n",
            "Recommand id: 176, Track name: sit awhile, Track genre&topic: country , personal\n",
            "Recommand id: 8, Track name: life changes, Track genre&topic: country , personal\n",
            "Recommand id: 90, Track name: alta, Track genre&topic: blues , personal\n",
            "Recommand id: 201, Track name: superposition, Track genre&topic: pop , personal\n",
            "Recommand id: 240, Track name: living it up, Track genre&topic: reggae , personal\n",
            "Recommand id: 104, Track name: you're the best thing yet, Track genre&topic: jazz , personal\n",
            "Recommand id: 98, Track name: feels, Track genre&topic: pop , emotion\n",
            "Recommand id: 113, Track name: wash away, Track genre&topic: reggae , personal\n",
            "Recommand id: 46, Track name: sunday morning, Track genre&topic: jazz , personal\n",
            "Recommand id: 131, Track name: boy in the bubble, Track genre&topic: pop , dark\n",
            "Recommand id: 231, Track name: (your love keeps lifting me) higher and higher, Track genre&topic: blues , lifestyle\n",
            "Recommand id: 45, Track name: it's only right, Track genre&topic: rock , lifestyle\n",
            "Recommand id: 39, Track name: will you be mine, Track genre&topic: jazz , sadness\n",
            "Recommand id: 125, Track name: live without limit, Track genre&topic: reggae , personal\n",
            "Recommand id: 173, Track name: everything to me, Track genre&topic: reggae , personal\n",
            "Recommand id: 163, Track name: pressure under fire, Track genre&topic: blues , personal\n",
            "Recommand id: 235, Track name: paranormal, Track genre&topic: blues , dark\n",
            "Recommand id: 99, Track name: hand of god, Track genre&topic: pop , personal\n",
            "Recommand id: 178, Track name: no one in the world, Track genre&topic: jazz , personal\n",
            "Recommand id: 237, Track name: do you really, Track genre&topic: jazz , lifestyle\n",
            "Recommand id: 34, Track name: around the corner, Track genre&topic: jazz , dark\n",
            "Recommand id: 105, Track name: the flame (is gone), Track genre&topic: jazz , sadness\n",
            "Recommand id: 111, Track name: happiness, Track genre&topic: rock , personal\n",
            "Recommand id: 133, Track name: light up the night, Track genre&topic: jazz , lifestyle\n",
            "Recommand id: 134, Track name: rocky road, Track genre&topic: reggae , personal\n",
            "Recommand id: 65, Track name: live well, Track genre&topic: rock , personal\n",
            "Recommand id: 42, Track name: donner bell, Track genre&topic: jazz , dark\n",
            "Recommand id: 6, Track name: no words, Track genre&topic: country , personal\n",
            "Recommand id: 151, Track name: still, Track genre&topic: country , dark\n",
            "Recommand id: 89, Track name: this love, Track genre&topic: jazz , personal\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def recommend(user_vecs, test_text, y_pred_test, N=34, sim=\"cosine\"):\n",
        "  score = []\n",
        "  for idx, text in enumerate(test_text):\n",
        "    topic = y_pred_test[idx]\n",
        "    if user_vecs[topic] is None: # skip whole process if user not interested in such topic\n",
        "      continue\n",
        "    vec_song = tfidf_global.transform([text])\n",
        "    if sim == \"cosine\": # cosine similarity\n",
        "      s = cosine_similarity(vec_song, user_vecs[topic])[0,0]\n",
        "    elif sim == \"dot\": # dot product\n",
        "      s = (vec_song @ user_vecs[topic].T)[0,0]\n",
        "    elif sim == \"jaccard\": # jaccard similarity\n",
        "      v1 = (vec_song>0).toarray().ravel().astype(bool)\n",
        "      v2 = (user_vecs[topic]>0).toarray().ravel().astype(bool)\n",
        "      inter = (v1 & v2).sum()\n",
        "      union = (v1 | v2).sum()\n",
        "      s = inter/union if union else 0\n",
        "    elif sim == \"euclidean\": # eculidean distance\n",
        "      from numpy.linalg import norm\n",
        "      d = norm(vec_song.toarray() - user_vecs[topic].toarray())\n",
        "      s = 1/(1+d)\n",
        "    score.append((idx, s))\n",
        "  return sorted(score, key=lambda x: x[1], reverse=True)[:N]\n",
        "rec1 = recommend(user1_topic_vecs, X_test, y_pred_test, N=34)\n",
        "print(rec1)\n",
        "for id, num in rec1: # actually wrong id for it's id in df.test which starts from 751, but here stars with 0\n",
        "  print(f\"Recommand id: {id}, Track name: {test.loc[id+750, 'track_name']}, Track genre&topic: {test.loc[id+750, 'genre']} , {test.loc[id+750, 'topic']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTRIKRpzBqcw"
      },
      "source": [
        "Create ground truth for all 3 users, which matched user's profile for predicted topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyKynrj2BqNJ",
        "outputId": "92a95c56-df74-475b-b982-2cf59a6cbb92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{6, 8, 10, 11, 12, 13, 16, 20, 22, 23, 29, 31, 34, 35, 39, 40, 41, 42, 45, 46, 51, 52, 58, 61, 65, 66, 67, 69, 74, 78, 81, 85, 89, 90, 98, 99, 104, 107, 109, 110, 111, 113, 114, 115, 121, 124, 125, 126, 130, 131, 133, 134, 137, 149, 150, 151, 154, 157, 160, 163, 164, 167, 170, 172, 173, 176, 178, 180, 183, 187, 188, 190, 191, 194, 196, 198, 201, 203, 204, 205, 206, 210, 211, 215, 216, 219, 221, 226, 230, 231, 235, 237, 240, 242}\n"
          ]
        }
      ],
      "source": [
        "def make_ground_truth(user_kw, df, y_pred):\n",
        "  gt = set()\n",
        "\n",
        "  for i, row in enumerate(df.itertuples()): # use enumerate because test starts from 751 as described before\n",
        "    #print(i,row)\n",
        "    topic = y_pred[i]\n",
        "    if topic not in user_kw: # skip unliked topic\n",
        "      continue\n",
        "    text = (row.artist_name + ' ' + row.track_name + ' ' + row.genre + ' ' + row.lyrics).lower()\n",
        "    #print(text)\n",
        "    if any(kw in text for kw in user_kw[topic]):\n",
        "      gt.add(i) # add to gt\n",
        "  return gt\n",
        "\n",
        "gt1 = make_ground_truth(user1_kw, test, y_pred_test)\n",
        "gt2 = make_ground_truth(user2_kw, test, y_pred_test)\n",
        "gt3 = make_ground_truth(user3_kw, test, y_pred_test)\n",
        "print(gt1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRKlL_8NGDDZ"
      },
      "source": [
        "Select\n",
        "\n",
        "precision, as ratio of user actually liked songs in top N\n",
        "\n",
        "recall, as true positive, ratio of user liked songs in top N in all user actually liked songs\n",
        "\n",
        "f1, as marmoic mean of precision and recall\n",
        "\n",
        "as evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "ppyd-baVHtoP"
      },
      "outputs": [],
      "source": [
        "def precision(recs, ground_truth):\n",
        "  rec_indices = [idx for idx, _ in recs]\n",
        "  hits = sum(1 for idx in rec_indices if idx in ground)\n",
        "  return hits / len(rec_indices) if rec_indices else 0\n",
        "\n",
        "def recall(recs, ground_truth):\n",
        "  rec_indices = [idx for idx, _ in recs]\n",
        "  return len(set(rec_indices) & ground) / len(ground) if ground else 0\n",
        "\n",
        "def f1cal(p, r):\n",
        "  return 2*p*r/(p+r) if (p+r)>0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWObhyt0MBIB"
      },
      "source": [
        "Under those metrics, generate top 34 recommendations using 3 of the algorithms  and evaluate them.\n",
        "\n",
        "For all users, the cosine and dot scores are almost same.I assume this is because I applied same (global) tfidf word list, thus when no additional normalization is performed on the user topic vector, the dot-product size sorting is consistent with the cosine one.\n",
        "\n",
        "Jaccard however is much worse. I assume this is because it only measures common features/union features, erases the weight information of tfidf, performs the worst in this scenario.\n",
        "\n",
        "About difference results of different users,(only consider cosine recommendation)\n",
        "\n",
        "for user1, high precision shows that lmost all the songs recommended in the top 34 are songs that he really likes, but low recall means that although it is very accurate, it only covers 35% of all the songs that he may like, many of the songs he likes are not ranked highly.\n",
        "\n",
        "for user2, precision is low but recall is as high as 0.82, so only about 25% of the top recommendations are what he really likes, but these recommendations cover almost all of his favorite songs.  assume this is because user2 only provides 2 liked topics, while the recommendation will give songs among basically all topics. So the program do knows what he likes well (as it's not much), but too much recommendations lowers the accuracy (still because he likes less).\n",
        "\n",
        "for user3, recommendations cover half of the hits and about 28% of the favorite songs, which is a (suspiciously) balanced state. I'm not sure that exact half is just a coincidance of is a bug.\n",
        "\n",
        "for all users, cosine sim is either slightly higher, or the same as dot product. Thus, the final algorithm choice is cosine similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "tZOj1qTAIBUt",
        "outputId": "353f40d3-da45-44be-f953-e0aee51cbd4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cosine\n",
            "dot\n",
            "jaccard\n",
            "cosine\n",
            "dot\n",
            "jaccard\n",
            "cosine\n",
            "dot\n",
            "jaccard\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_res\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"User1\",\n          \"User2\",\n          \"User3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sim\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"cosine\",\n          \"dot\",\n          \"jaccard\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3021373942399015,\n        \"min\": 0.17647058823529413,\n        \"max\": 0.9705882352941176,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9705882352941176,\n          0.47058823529411764,\n          0.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22112089077988545,\n        \"min\": 0.16666666666666666,\n        \"max\": 0.8181818181818182,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.35106382978723405,\n          0.1702127659574468,\n          0.2833333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10880036140303524,\n        \"min\": 0.21276595744680848,\n        \"max\": 0.515625,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.515625,\n          0.25,\n          0.36170212765957444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_res"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-11c20a0e-9a51-4c91-8670-cc2928e0f1a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user</th>\n",
              "      <th>sim</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>User1</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.351064</td>\n",
              "      <td>0.515625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>User1</td>\n",
              "      <td>dot</td>\n",
              "      <td>0.970588</td>\n",
              "      <td>0.351064</td>\n",
              "      <td>0.515625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>User1</td>\n",
              "      <td>jaccard</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>User2</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>User2</td>\n",
              "      <td>dot</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.311111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>User2</td>\n",
              "      <td>jaccard</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>User3</td>\n",
              "      <td>cosine</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.361702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>User3</td>\n",
              "      <td>dot</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>0.361702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>User3</td>\n",
              "      <td>jaccard</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.212766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11c20a0e-9a51-4c91-8670-cc2928e0f1a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11c20a0e-9a51-4c91-8670-cc2928e0f1a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11c20a0e-9a51-4c91-8670-cc2928e0f1a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e44380ed-c757-4b50-9e9b-471ed53dde07\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e44380ed-c757-4b50-9e9b-471ed53dde07')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e44380ed-c757-4b50-9e9b-471ed53dde07 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1f37bb68-2c49-491a-a879-7b9e1b8cc3de\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_res')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1f37bb68-2c49-491a-a879-7b9e1b8cc3de button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_res');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    user      sim  Precision    Recall        F1\n",
              "0  User1   cosine   0.970588  0.351064  0.515625\n",
              "1  User1      dot   0.970588  0.351064  0.515625\n",
              "2  User1  jaccard   0.470588  0.170213  0.250000\n",
              "3  User2   cosine   0.264706  0.818182  0.400000\n",
              "4  User2      dot   0.205882  0.636364  0.311111\n",
              "5  User2  jaccard   0.176471  0.545455  0.266667\n",
              "6  User3   cosine   0.500000  0.283333  0.361702\n",
              "7  User3      dot   0.500000  0.283333  0.361702\n",
              "8  User3  jaccard   0.294118  0.166667  0.212766"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "users = {'User1': (user1_topic_vecs, gt1), 'User2': (user2_topic_vecs, gt2), 'User3': (user3_topic_vecs, gt3)}\n",
        "\n",
        "results = []\n",
        "for uname, (u_vecs, ground) in users.items():\n",
        "  for sim in ['cosine','dot','jaccard']:\n",
        "    print(sim)\n",
        "    recs = recommend(u_vecs, X_test, y_pred_test, N=34, sim=sim)\n",
        "    #print(recs)\n",
        "    #print(gt1)\n",
        "\n",
        "    p = precision(recs, ground)\n",
        "    r = recall(recs, ground)\n",
        "    f1 = f1cal(p, r)\n",
        "    results.append({'user': uname, 'sim': sim, 'Precision': p, 'Recall': r, 'F1': f1})\n",
        "\n",
        "df_res = pd.DataFrame(results)\n",
        "display(df_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3Yng_SEXfJO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XgcfWEc7UN-Z",
        "X2vwQM8FPj0m",
        "r8d8htb-T38P"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
